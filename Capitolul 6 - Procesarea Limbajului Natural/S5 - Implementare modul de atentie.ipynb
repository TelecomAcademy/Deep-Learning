{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.array([1, 0, 0])\n",
    "w2 = np.array([0, 1, 0])\n",
    "w3 = np.array([1, 1, 0])\n",
    "w4 = np.array([0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "W_Q = np.random.randint(3, size=(3, 3))\n",
    "W_K = np.random.randint(3, size=(3, 3))\n",
    "W_V = np.random.randint(3, size=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = np.dot(w1, W_Q)\n",
    "key_1 = np.dot(w1, W_K)\n",
    "value_1 = np.dot(w1, W_V)\n",
    " \n",
    "query_2 = np.dot(w2, W_Q)\n",
    "key_2 = np.dot(w2, W_K)\n",
    "value_2 = np.dot(w2, W_V)\n",
    " \n",
    "query_3 = np.dot(w3, W_Q)\n",
    "key_3 = np.dot(w3, W_K)\n",
    "value_3 = np.dot(w3, W_V)\n",
    " \n",
    "query_4 = np.dot(w4, W_Q)\n",
    "key_4 = np.dot(w4, W_K)\n",
    "value_4 = np.dot(w4, W_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generam scorurile de atentie pentru primul cuvant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([\n",
    "    np.dot(query_1, key_1),\n",
    "    np.dot(query_1, key_2),\n",
    "    np.dot(query_1, key_3),\n",
    "    np.dot(query_1, key_4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este o practica comuna sa impartim scorurile la radical din dimensiunea vectorilor de chei\n",
    "weights = softmax(scores / key_1.shape[0] ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98522025 1.74174051 0.75652026]\n"
     ]
    }
   ],
   "source": [
    "attention = (weights[0] * value_1) + (weights[1] * value_2) + (weights[2] * value_3) + (weights[3] * value_4)\n",
    " \n",
    "print(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generam pentru toate cuvintele scorurile de atentie folosind o implementare vectorizata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.array([\n",
    "    w1,\n",
    "    w2,\n",
    "    w3,\n",
    "    w4\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.dot(words, W_Q)\n",
    "K = np.dot(words, W_K)\n",
    "V = np.dot(words, W_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.dot(Q, K.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  2, 10,  2],\n",
       "       [ 4,  0,  4,  0],\n",
       "       [12,  2, 14,  2],\n",
       "       [10,  4, 14,  3]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = softmax(scores / K.shape[1] ** 0.5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98522025 1.74174051 0.75652026]\n",
      " [0.90965265 1.40965265 0.5       ]\n",
      " [0.99851226 1.75849334 0.75998108]\n",
      " [0.99560386 1.90407309 0.90846923]]\n"
     ]
    }
   ],
   "source": [
    "attention = np.dot(weights, V)\n",
    " \n",
    "print(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW\n",
    "Adapteaza codul de mai sus pentru a implementa modulul de atentie Bahdanau."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
