{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.type = 'Softmax'\n",
    "        self.eps = 1e-15\n",
    "\n",
    "    def forward(self, Z):\n",
    "        self.Z = Z\n",
    "\n",
    "        t = np.exp(Z - np.max(Z, axis=0))\n",
    "        self.A =  t / np.sum(t, axis=0, keepdims=True)\n",
    "\n",
    "        return self.A\n",
    "\n",
    "class Tanh:\n",
    "    def __init__(self):\n",
    "        self.type = 'Tanh'\n",
    "\n",
    "    def forward(self, Z):\n",
    "        self.A = np.tanh(Z)\n",
    "\n",
    "        return self.A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        dZ = dA * (1 - np.power(self.A, 2))\n",
    "\n",
    "        return dZ\n",
    "    \n",
    "class CrossEntropyLoss:\n",
    "    def __init__(self):\n",
    "        self.type = 'CELoss'\n",
    "        self.eps = 1e-15\n",
    "        self.softmax = Softmax()\n",
    "    \n",
    "    def forward(self, Y_hat, Y):\n",
    "        self.Y = Y\n",
    "        self.Y_hat = Y_hat\n",
    "\n",
    "        _loss = - Y * np.log(self.Y_hat)\n",
    "        loss = np.sum(_loss, axis=0).mean()\n",
    "\n",
    "        return np.squeeze(loss) \n",
    "\n",
    "    def backward(self):\n",
    "        grad = self.Y_hat - self.Y\n",
    "        \n",
    "        return grad\n",
    "\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self, lr=0.0075, beta=0.9):\n",
    "        self.beta = beta\n",
    "        self.lr = lr\n",
    "\n",
    "    def optim(self, weights, gradients, velocities=None):\n",
    "        if velocities is None: velocities = [0 for weight in weights]\n",
    "\n",
    "        velocities = self._update_velocities(\n",
    "            gradients, self.beta, velocities\n",
    "        )\n",
    "        new_weights = []\n",
    "\n",
    "        for weight, velocity in zip(weights, velocities):\n",
    "            weight -= self.lr * velocity\n",
    "            new_weights.append(weight)\n",
    "\n",
    "        return new_weights, velocities\n",
    "\n",
    "    def _update_velocities(self, gradients, beta, velocities):\n",
    "        new_velocities = []\n",
    "\n",
    "        for gradient, velocity in zip(gradients, velocities):\n",
    "\n",
    "            new_velocity = beta * velocity + (1 - beta) * gradient\n",
    "            new_velocities.append(new_velocity)\n",
    "\n",
    "        return new_velocities\n",
    "\n",
    "\n",
    "def one_hot_encoding(input, size):\n",
    "    output = []\n",
    "\n",
    "    for index, num in enumerate(input):\n",
    "        one_hot = np.zeros((size,1))\n",
    "\n",
    "        if (num != None):\n",
    "            one_hot[num] = 1\n",
    "    \n",
    "        output.append(one_hot)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    \"\"\"\n",
    "    Implementare retea recurenta\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        \"\"\"\n",
    "        Initializare parametrii pe baza hiperparametrilor.\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        params = self._initialize_parameters(\n",
    "                input_dim, output_dim, hidden_dim\n",
    "        )\n",
    "        self.Wya, self.Wax, self.Waa, self.by, self.b = params\n",
    "        self.softmax = Softmax()\n",
    "        self.oparams = None\n",
    "\n",
    "    def forward(self, input_X):\n",
    "        \"\"\"\n",
    "        Propagarea inainte prin retea\n",
    "        \"\"\"\n",
    "        self.input_X = input_X\n",
    " \n",
    "        self.layers_tanh = [Tanh() for x in input_X]\n",
    "        hidden = np.zeros((self.hidden_dim , 1))\n",
    "\n",
    "        self.hidden_list = [hidden]\n",
    "        self.y_preds = []\n",
    "\n",
    "        for input_x, layer_tanh in zip(input_X, self.layers_tanh):\n",
    "            input_tanh = np.dot(self.Wax, input_x) + np.dot(self.Waa, hidden) + self.b\n",
    "            hidden = layer_tanh.forward(input_tanh)\n",
    "            self.hidden_list.append(hidden)\n",
    "\n",
    "            input_softmax = np.dot(self.Wya, hidden) + self.by\n",
    "            y_pred = self.softmax.forward(input_softmax)\n",
    "            self.y_preds.append(y_pred)\n",
    "\n",
    "        return self.y_preds\n",
    "\n",
    "    def loss(self, Y):\n",
    "        \"\"\"\n",
    "        Functie de cost a retelei pentru clasificare.\n",
    "        \"\"\"\n",
    "        self.Y = Y\n",
    "        self.layers_loss = [CrossEntropyLoss() for y in self.Y]\n",
    "        cost = 0\n",
    "\n",
    "        for y_pred, y, layer in zip(self.y_preds, self.Y, self.layers_loss):\n",
    "            cost += layer.forward(y_pred, y)\n",
    "\n",
    "        return cost\n",
    "\n",
    "    def backward(self):  \n",
    "        \"\"\"\n",
    "        Propagarea inapoi prin timp in reteaua recurenta.\n",
    "        \"\"\"\n",
    "        gradients = self._define_gradients()\n",
    "        self.dWax, self.dWaa, self.dWya, self.db, self.dby, dhidden_next = gradients\n",
    "\n",
    "        for index, layer_loss in reversed(list(enumerate(self.layers_loss))):\n",
    "            dy = layer_loss.backward()\n",
    "\n",
    "            # hidden actual\n",
    "            hidden = self.hidden_list[index + 1]\n",
    "            hidden_prev = self.hidden_list[index]\n",
    "\n",
    "            # gradients y\n",
    "            self.dWya += np.dot(dy, hidden.T)\n",
    "            self.dby += dy\n",
    "            dhidden = np.dot(self.Wya.T, dy) + dhidden_next\n",
    "\n",
    "            # gradients a\n",
    "            dtanh = self.layers_tanh[index].backward(dhidden)\n",
    "            self.db += dtanh\n",
    "            self.dWax += np.dot(dtanh, self.input_X[index].T)\n",
    "            self.dWaa += np.dot(dtanh, hidden_prev.T)\n",
    "            dhidden_next = np.dot(self.Waa.T, dtanh)\n",
    "\n",
    "    def clip(self, clip_value):\n",
    "        \"\"\"\n",
    "        Gradient clipping/limitarea valorilor pentru a evita problema exploding gradients.\n",
    "        \"\"\"\n",
    "        for gradient in [self.dWax, self.dWaa, self.dWya, self.db, self.dby]:\n",
    "            np.clip(gradient, -clip_value, clip_value, out=gradient)\n",
    "\n",
    "    def optimize(self, method):\n",
    "        \"\"\"\n",
    "        Optimizare retea cu o metoda custom\n",
    "        \"\"\"\n",
    "        weights = [self.Wya, self.Wax, self.Waa, self.by, self.b]\n",
    "        gradients = [self.dWya, self.dWax, self.dWaa, self.dby, self.db]\n",
    "\n",
    "        weights, self.oparams = method.optim(weights, gradients, self.oparams)\n",
    "        self.Wya, self.Wax, self.Waa, self.by, self.b = weights\n",
    "        \n",
    "    \n",
    "    def generate_names(\n",
    "        self, index_to_character\n",
    "    ):\n",
    "        letter = None\n",
    "        indexes = list(index_to_character.keys())\n",
    "\n",
    "        letter_x = np.zeros((self.input_dim, 1))\n",
    "        name = []\n",
    "\n",
    "        # similar to forward propagation.\n",
    "        layer_tanh = Tanh()\n",
    "        hidden = np.zeros((self.hidden_dim , 1))\n",
    "\n",
    "        while letter != '\\n' and len(name)<15:\n",
    "\n",
    "            input_tanh = np.dot(self.Wax, letter_x) + np.dot(self.Waa, hidden) + self.b\n",
    "            hidden = layer_tanh.forward(input_tanh)\n",
    "\n",
    "            input_softmax = np.dot(self.Wya, hidden) + self.by\n",
    "            y_pred = self.softmax.forward(input_softmax)\n",
    "\n",
    "            index = np.random.choice(indexes, p=y_pred.ravel())\n",
    "            letter = index_to_character[index]\n",
    "\n",
    "            name.append(letter)\n",
    "\n",
    "            letter_x = np.zeros((self.input_dim, 1))\n",
    "            letter_x[index] = 1\n",
    "\n",
    "        return \"\".join(name)\n",
    "\n",
    "\n",
    "    def _initialize_parameters(self, input_dim, output_dim, hidden_dim):\n",
    "        \"\"\"\n",
    "        Initializare random a parametrilor\n",
    "        \"\"\"\n",
    "        den = np.sqrt(hidden_dim)\n",
    "\n",
    "        weights_y = np.random.randn(output_dim, hidden_dim) / den\n",
    "        bias_y = np.zeros((output_dim, 1))\n",
    "\n",
    "        weights_ax = np.random.randn(hidden_dim, input_dim) / den\n",
    "        weights_aa = np.random.randn(hidden_dim, hidden_dim) / den\n",
    "        bias = np.zeros((hidden_dim, 1))\n",
    "\n",
    "        return weights_y, weights_ax, weights_aa, bias_y, bias\n",
    "\n",
    "\n",
    "    def _define_gradients(self):\n",
    "        \"\"\"\n",
    "        Initializare gradienti\n",
    "        \"\"\"\n",
    "        dWax = np.zeros_like(self.Wax)\n",
    "        dWaa = np.zeros_like(self.Waa)\n",
    "        dWya = np.zeros_like(self.Wya)\n",
    "\n",
    "        db = np.zeros_like(self.b)\n",
    "        dby = np.zeros_like(self.by)\n",
    "\n",
    "        da_next = np.zeros_like(self.hidden_list[0])\n",
    "\n",
    "        return dWax, dWaa, dWya, db, dby, da_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_names = open('nume.txt', 'r').read()\n",
    "person_names= person_names.lower()\n",
    "characters = list(set(person_names))\n",
    " \n",
    "character_to_index = {character:index for index,character in enumerate(sorted(characters))}\n",
    "index_to_character = {index:character for index,character in enumerate(sorted(characters))}\n",
    " \n",
    "with open(\"nume.txt\") as f:\n",
    "    person_names = f.readlines()\n",
    "\n",
    "\n",
    "person_names = [name.lower().strip() for name in person_names]\n",
    "np.random.shuffle(person_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100001\n",
    "input_dim = 27\n",
    "output_dim = 27\n",
    "hidden_dim = 50\n",
    " \n",
    "# initialize and define the model hyperparamaters\n",
    "model = RNN(input_dim, output_dim, hidden_dim)\n",
    "optim = SGD(lr=0.001)\n",
    "costs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 29.549004\n",
      "Names created: \n",
      "\n",
      "uxbkcbonhmctijd\n",
      "wbyruj\n",
      "\n",
      "nsvyvjiefdkqzhb\n",
      "zlputwkuhecealh\n",
      "Cost after iteration 10000: 14.830316\n",
      "Names created: \n",
      "\n",
      "rilrll\n",
      "\n",
      "fajis\n",
      "\n",
      "miroant\n",
      "\n",
      "yareta\n",
      "\n",
      "Cost after iteration 20000: 14.754257\n",
      "Names created: \n",
      "\n",
      "ajzre\n",
      "\n",
      "tellef\n",
      "\n",
      "totira\n",
      "\n",
      "hinnein\n",
      "\n",
      "Cost after iteration 30000: 20.483688\n",
      "Names created: \n",
      "\n",
      "xrauri\n",
      "\n",
      "biestaru\n",
      "\n",
      "gryshes\n",
      "\n",
      "cwiryy\n",
      "\n",
      "Cost after iteration 40000: 25.459537\n",
      "Names created: \n",
      "\n",
      "yterlicto\n",
      "\n",
      "cerys\n",
      "\n",
      "ryen\n",
      "\n",
      "jakin\n",
      "\n",
      "Cost after iteration 50000: 15.062868\n",
      "Names created: \n",
      "\n",
      "jeza\n",
      "\n",
      "jodohra\n",
      "\n",
      "eafha\n",
      "\n",
      "rasen\n",
      "\n",
      "Cost after iteration 60000: 22.603483\n",
      "Names created: \n",
      "\n",
      "drionelle\n",
      "\n",
      "coreille\n",
      "\n",
      "yldi\n",
      "\n",
      "maliano\n",
      "\n",
      "Cost after iteration 70000: 12.688049\n",
      "Names created: \n",
      "\n",
      "jada\n",
      "\n",
      "kishe\n",
      "\n",
      "idshan\n",
      "\n",
      "kaniea\n",
      "\n",
      "Cost after iteration 80000: 13.247217\n",
      "Names created: \n",
      "\n",
      "fardany\n",
      "\n",
      "ahonachie\n",
      "\n",
      "uy\n",
      "\n",
      "teyuda\n",
      "\n",
      "Cost after iteration 90000: 15.419439\n",
      "Names created: \n",
      "\n",
      "anizau\n",
      "\n",
      "chalita\n",
      "\n",
      "tavewna\n",
      "\n",
      "kileye\n",
      "\n",
      "Cost after iteration 100000: 17.492231\n",
      "Names created: \n",
      "\n",
      "akuyla\n",
      "\n",
      "darir\n",
      "\n",
      "rizida\n",
      "\n",
      "calles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "     \n",
    "    # create the X inputs and Y labels\n",
    "    index = epoch % len(person_names)\n",
    "    X = [None] + [character_to_index[ch] for ch in person_names[index]] \n",
    "    Y = X[1:] + [character_to_index[\"\\n\"]]\n",
    " \n",
    "    # transform the input X and label Y into one hot enconding.\n",
    "    X = one_hot_encoding(X, input_dim)\n",
    "    Y = one_hot_encoding(Y, output_dim)\n",
    "     \n",
    "    # steps of the model\n",
    "    model.forward(X)\n",
    "    cost = model.loss(Y)\n",
    "    model.backward()\n",
    "    # clip gradients\n",
    "    model.clip(clip_value=1)\n",
    "    # optimize\n",
    "    model.optimize(optim)\n",
    " \n",
    "    if epoch % 10000 == 0:\n",
    "        print (\"Cost after iteration %d: %f\" % (epoch, cost))\n",
    "        costs.append(cost)\n",
    " \n",
    "        print('Names created:', '\\n')\n",
    "        for i in range(4):\n",
    "            name = model.generate_names(index_to_character)\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
