{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid_derivat(dA, x):\n",
    "    \"\"\"\n",
    "    sigmoid'(x) = x' * sigmoid(x) * (1 - sigmoid(x))\n",
    "    \"\"\"\n",
    "    f = sigmoid(x)\n",
    "    \n",
    "    return dA * f * (1 - f)\n",
    "\n",
    "def relu_derivat(dA, x):\n",
    "    \"\"\" relu'(x) = [0, daca x <=0 altfel 1] * x' \"\"\"\n",
    "    dX = np.array(dA, copy=True)\n",
    "    dX[x <= 0] = 0\n",
    "    \n",
    "    return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce(y, y_hat):\n",
    "    n = y.shape[1]\n",
    "    \n",
    "    loss = (-1 / n) * (np.dot(y, np.log(y_hat).T) + np.dot(1 - y, np.log(1 - y_hat).T))\n",
    "    \n",
    "    return np.squeeze(loss)\n",
    "\n",
    "def accuracy_score(y, y_hat):\n",
    "    classes = (y_hat >= 0.5).astype(int)\n",
    "\n",
    "    return (classes == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    \"\"\"\n",
    "    Varianta definire MLP cu specificare input si output pentru fiecare unitate.\n",
    "    \"\"\"\n",
    "    def __init__(self, architecture, random_seed=42):\n",
    "        np.random.seed(random_seed)\n",
    "        \n",
    "        self.activation_functions = {\n",
    "            'sigmoid': sigmoid,\n",
    "            'relu': relu\n",
    "        }\n",
    "        \n",
    "        self.derivatives = {\n",
    "            'relu': relu_derivat,\n",
    "            'sigmoid': sigmoid_derivat\n",
    "        }\n",
    "        \n",
    "        \n",
    "        number_of_layers = len(architecture)\n",
    "        params_values = {}\n",
    "\n",
    "        for idx, layer in enumerate(architecture):\n",
    "            layer_idx = idx + 1\n",
    "            \n",
    "            layer_input_size = layer[\"input_dim\"]\n",
    "            \n",
    "            layer_output_size = layer[\"units\"]\n",
    "\n",
    "            params_values['W' + str(layer_idx)] = np.random.randn(layer_output_size, layer_input_size) * 0.1\n",
    "            \n",
    "            params_values['b' + str(layer_idx)] = np.random.randn(layer_output_size, 1) * 0.1\n",
    "            \n",
    "            \n",
    "        self.params = params_values\n",
    "        self.architecture = architecture\n",
    "        \n",
    "    def summary(self):\n",
    "        print(\"{:^15s} {:^15s} {:^15s} {:^15s} {:^15s} {:^15s} \\n\".format(\n",
    "            \"Input shape\",\n",
    "            \"Output shape\",\n",
    "            \"Weights shape\",\n",
    "            \"Bias shape\",\n",
    "            \"Activation\",\n",
    "            \"Params\"\n",
    "        ))\n",
    "        print(\"{:_<100s}\".format(''))\n",
    "        total_params = 0\n",
    "        for idx, layer in enumerate(self.architecture):\n",
    "            layer_idx = idx + 1\n",
    "            in_shape = layer[\"input_dim\"]\n",
    "            out_shape = layer[\"units\"]\n",
    "            \n",
    "            weights_shape = self.params['W' + str(layer_idx)].shape\n",
    "            bias_shape = self.params['b' + str(layer_idx)].shape\n",
    "            \n",
    "            activation = layer[\"activation\"]\n",
    "            \n",
    "            weights_params = 1\n",
    "            for dim in weights_shape:\n",
    "                weights_params *= dim\n",
    "            \n",
    "            bias_params = 1\n",
    "            for dim in bias_shape:\n",
    "                bias_params *= dim\n",
    "            \n",
    "            num_params = bias_params + weights_params\n",
    "            total_params += num_params\n",
    "            \n",
    "            print(\"{:^15d} {:^15d} {:^15s} {:^15s} {:^15s} {:^15d} \\n\".format(\n",
    "                in_shape,\n",
    "                out_shape,\n",
    "                str(weights_shape),\n",
    "                str(bias_shape),\n",
    "                activation,\n",
    "                num_params\n",
    "            ))\n",
    "            print(\"-\"*100)\n",
    "            \n",
    "        print(\"Total number of parameters: {}\".format(total_params))\n",
    "\n",
    "    def forward(self, w, b, x, activation='relu'):\n",
    "        z = np.dot(w, x) + b\n",
    "    \n",
    "        return self.activation_functions[activation](z), z\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\" Functie cu care realizam predictii prin metoda propagarii inainte. \"\"\"\n",
    "        memory = {}\n",
    "        current_activation = x\n",
    "\n",
    "        for idx, layer in enumerate(self.architecture):\n",
    "            layer_idx = idx + 1\n",
    "            previous_activation = current_activation\n",
    "            \n",
    "            activation_function = layer[\"activation\"]\n",
    "            \n",
    "            w = self.params[\"W\" + str(layer_idx)]\n",
    "            \n",
    "            b = self.params[\"b\" + str(layer_idx)]\n",
    "\n",
    "            current_activation, z = self.forward(w, b, previous_activation, activation_function)\n",
    "\n",
    "            memory[\"x\" + str(idx)] = previous_activation\n",
    "            memory[\"z\" + str(layer_idx)] = z\n",
    "\n",
    "        return current_activation, memory\n",
    "    \n",
    "    def backward(self, dA_curr, W_curr, b_curr, Z_curr, A_prev, activation=\"relu\"):\n",
    "        # number of examples\n",
    "        m = A_prev.shape[1]\n",
    "\n",
    "        # selection of activation function\n",
    "        if activation is \"relu\":\n",
    "            backward_activation_func = relu_derivat\n",
    "        elif activation is \"sigmoid\":\n",
    "            backward_activation_func = sigmoid_derivat\n",
    "        else:\n",
    "            raise Exception('Non-supported activation function')\n",
    "\n",
    "        # calculation of the activation function derivative\n",
    "        dZ_curr = backward_activation_func(dA_curr, Z_curr)\n",
    "\n",
    "        # derivative of the matrix W\n",
    "        dW_curr = np.dot(dZ_curr, A_prev.T) / m\n",
    "        # derivative of the vector b\n",
    "        db_curr = np.sum(dZ_curr, axis=1, keepdims=True) / m\n",
    "        # derivative of the matrix A_prev\n",
    "        dA_prev = np.dot(W_curr.T, dZ_curr)\n",
    "\n",
    "        return dA_prev, dW_curr, db_curr\n",
    "    \n",
    "    def backward_propagation(self, Y_hat, Y, memory):\n",
    "        grads_values = {}\n",
    "    \n",
    "        # number of examples\n",
    "        m = Y.shape[1]\n",
    "        # a hack ensuring the same shape of the prediction vector and labels vector\n",
    "        Y = Y.reshape(Y_hat.shape)\n",
    "\n",
    "        # initiation of gradient descent algorithm\n",
    "        dA_prev = - (np.divide(Y, Y_hat) - np.divide(1 - Y, 1 - Y_hat));\n",
    "\n",
    "        for layer_idx_prev, layer in reversed(list(enumerate(self.architecture))):\n",
    "            # we number network layers from 1\n",
    "            layer_idx_curr = layer_idx_prev + 1\n",
    "            # extraction of the activation function for the current layer\n",
    "            activ_function_curr = layer[\"activation\"]\n",
    "\n",
    "            dA_curr = dA_prev\n",
    "\n",
    "            A_prev = memory[\"x\" + str(layer_idx_prev)]\n",
    "            Z_curr = memory[\"z\" + str(layer_idx_curr)]\n",
    "\n",
    "            W_curr = self.params[\"W\" + str(layer_idx_curr)]\n",
    "            b_curr = self.params[\"b\" + str(layer_idx_curr)]\n",
    "\n",
    "            dA_prev, dW_curr, db_curr = self.backward(\n",
    "                dA_curr, W_curr, b_curr, Z_curr, A_prev, activ_function_curr)\n",
    "\n",
    "            grads_values[\"dW\" + str(layer_idx_curr)] = dW_curr\n",
    "            grads_values[\"db\" + str(layer_idx_curr)] = db_curr\n",
    "\n",
    "        return grads_values\n",
    "    \n",
    "    def update(self, grads_values, learning_rate):\n",
    "        for layer_idx, layer in enumerate(self.architecture, 1):\n",
    "            self.params[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "            self.params[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "            \n",
    "    def train(self, X, Y, epochs, learning_rate):\n",
    "        cost_history = []\n",
    "        accuracy_history = []\n",
    "\n",
    "        for i in range(epochs):\n",
    "            Y_hat, mem = self.predict(X)\n",
    "            cost = bce(Y, Y_hat)\n",
    "            \n",
    "            cost_history.append(cost)\n",
    "            accuracy = accuracy_score(Y, Y_hat)\n",
    "            accuracy_history.append(accuracy)\n",
    "\n",
    "            grads_values = self.backward_propagation(Y_hat, Y, mem)\n",
    "            \n",
    "            self.update(grads_values, learning_rate)\n",
    "            \n",
    "            if(i % 50 == 0):\n",
    "                print(\"Iteration: {:05} - cost: {:.5f} - accuracy: {:.5f}\".format(i, cost, accuracy))\n",
    "\n",
    "        return cost_history, accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = [\n",
    "    {\n",
    "        \"input_dim\": 2,\n",
    "        \"units\": 25,\n",
    "        \"activation\": \"relu\"\n",
    "    },\n",
    "    {\n",
    "        \"input_dim\": 25,\n",
    "        \"units\": 50,\n",
    "        \"activation\": \"relu\"\n",
    "    },\n",
    "    {\n",
    "        \"input_dim\": 50,\n",
    "        \"units\": 50,\n",
    "        \"activation\": \"relu\"\n",
    "    },\n",
    "    {\n",
    "        \"input_dim\": 50,\n",
    "        \"units\": 25,\n",
    "        \"activation\": \"relu\"\n",
    "    },\n",
    "    {\n",
    "        \"input_dim\": 25,\n",
    "        \"units\": 1,\n",
    "        \"activation\": \"sigmoid\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLP(architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Input shape    Output shape    Weights shape    Bias shape      Activation        Params      \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "       2              25            (25, 2)         (25, 1)          relu             75        \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "      25              50           (50, 25)         (50, 1)          relu            1300       \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "      50              50           (50, 50)         (50, 1)          relu            2550       \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "      50              25           (25, 50)         (25, 1)          relu            1275       \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "      25               1            (1, 25)         (1, 1)          sigmoid           26        \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Total number of parameters: 5226\n"
     ]
    }
   ],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples = 1000, noise=0.2, random_state=100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot, dots colored by class value\n",
    "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "colors = {0:'red', 1:'blue'}\n",
    "fig, ax = plt.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 00000 - cost: 0.69509 - accuracy: 0.49556\n",
      "Iteration: 00050 - cost: 0.69228 - accuracy: 0.49667\n",
      "Iteration: 00100 - cost: 0.69102 - accuracy: 0.50444\n",
      "Iteration: 00150 - cost: 0.68836 - accuracy: 0.67556\n",
      "Iteration: 00200 - cost: 0.68028 - accuracy: 0.82444\n",
      "Iteration: 00250 - cost: 0.64183 - accuracy: 0.84000\n",
      "Iteration: 00300 - cost: 0.43950 - accuracy: 0.85444\n",
      "Iteration: 00350 - cost: 0.29377 - accuracy: 0.87667\n",
      "Iteration: 00400 - cost: 0.28068 - accuracy: 0.87778\n",
      "Iteration: 00450 - cost: 0.27648 - accuracy: 0.88000\n",
      "Iteration: 00500 - cost: 0.27201 - accuracy: 0.88111\n",
      "Iteration: 00550 - cost: 0.26648 - accuracy: 0.88000\n",
      "Iteration: 00600 - cost: 0.25979 - accuracy: 0.88000\n",
      "Iteration: 00650 - cost: 0.25365 - accuracy: 0.88333\n",
      "Iteration: 00700 - cost: 0.24837 - accuracy: 0.88556\n",
      "Iteration: 00750 - cost: 0.24416 - accuracy: 0.88667\n",
      "Iteration: 00800 - cost: 0.23042 - accuracy: 0.89222\n",
      "Iteration: 00850 - cost: 0.21399 - accuracy: 0.90000\n",
      "Iteration: 00900 - cost: 0.18444 - accuracy: 0.91667\n",
      "Iteration: 00950 - cost: 0.15038 - accuracy: 0.94444\n",
      "Iteration: 01000 - cost: 0.11602 - accuracy: 0.95333\n",
      "Iteration: 01050 - cost: 0.09721 - accuracy: 0.96111\n",
      "Iteration: 01100 - cost: 0.09349 - accuracy: 0.95889\n",
      "Iteration: 01150 - cost: 0.08921 - accuracy: 0.96222\n",
      "Iteration: 01200 - cost: 0.09031 - accuracy: 0.96000\n",
      "Iteration: 01250 - cost: 0.08407 - accuracy: 0.96222\n",
      "Iteration: 01300 - cost: 0.08815 - accuracy: 0.96000\n",
      "Iteration: 01350 - cost: 0.08188 - accuracy: 0.96556\n",
      "Iteration: 01400 - cost: 0.08618 - accuracy: 0.96222\n",
      "Iteration: 01450 - cost: 0.08196 - accuracy: 0.96222\n",
      "Iteration: 01500 - cost: 0.07951 - accuracy: 0.96667\n",
      "Iteration: 01550 - cost: 0.08031 - accuracy: 0.96111\n",
      "Iteration: 01600 - cost: 0.07941 - accuracy: 0.96111\n",
      "Iteration: 01650 - cost: 0.07785 - accuracy: 0.96444\n",
      "Iteration: 01700 - cost: 0.07713 - accuracy: 0.96444\n",
      "Iteration: 01750 - cost: 0.07512 - accuracy: 0.96778\n",
      "Iteration: 01800 - cost: 0.07962 - accuracy: 0.96222\n",
      "Iteration: 01850 - cost: 0.07391 - accuracy: 0.96333\n",
      "Iteration: 01900 - cost: 0.07391 - accuracy: 0.96444\n",
      "Iteration: 01950 - cost: 0.07411 - accuracy: 0.96444\n",
      "Iteration: 02000 - cost: 0.07246 - accuracy: 0.96556\n",
      "Iteration: 02050 - cost: 0.07037 - accuracy: 0.96667\n",
      "Iteration: 02100 - cost: 0.07001 - accuracy: 0.96778\n",
      "Iteration: 02150 - cost: 0.07045 - accuracy: 0.96556\n",
      "Iteration: 02200 - cost: 0.06929 - accuracy: 0.96667\n",
      "Iteration: 02250 - cost: 0.06902 - accuracy: 0.96667\n",
      "Iteration: 02300 - cost: 0.06858 - accuracy: 0.96667\n",
      "Iteration: 02350 - cost: 0.06833 - accuracy: 0.96667\n",
      "Iteration: 02400 - cost: 0.06847 - accuracy: 0.96778\n",
      "Iteration: 02450 - cost: 0.06782 - accuracy: 0.96778\n",
      "Iteration: 02500 - cost: 0.06761 - accuracy: 0.96778\n",
      "Iteration: 02550 - cost: 0.06675 - accuracy: 0.96889\n",
      "Iteration: 02600 - cost: 0.06674 - accuracy: 0.96889\n",
      "Iteration: 02650 - cost: 0.06666 - accuracy: 0.96889\n",
      "Iteration: 02700 - cost: 0.06583 - accuracy: 0.97000\n",
      "Iteration: 02750 - cost: 0.06554 - accuracy: 0.97000\n",
      "Iteration: 02800 - cost: 0.06525 - accuracy: 0.97000\n",
      "Iteration: 02850 - cost: 0.06511 - accuracy: 0.97000\n",
      "Iteration: 02900 - cost: 0.06473 - accuracy: 0.97000\n",
      "Iteration: 02950 - cost: 0.06449 - accuracy: 0.97000\n",
      "Iteration: 03000 - cost: 0.06450 - accuracy: 0.97000\n",
      "Iteration: 03050 - cost: 0.06454 - accuracy: 0.97000\n",
      "Iteration: 03100 - cost: 0.06526 - accuracy: 0.96667\n",
      "Iteration: 03150 - cost: 0.06388 - accuracy: 0.97000\n",
      "Iteration: 03200 - cost: 0.06427 - accuracy: 0.97000\n",
      "Iteration: 03250 - cost: 0.06501 - accuracy: 0.96889\n",
      "Iteration: 03300 - cost: 0.06370 - accuracy: 0.97000\n",
      "Iteration: 03350 - cost: 0.06512 - accuracy: 0.96778\n",
      "Iteration: 03400 - cost: 0.06406 - accuracy: 0.96889\n",
      "Iteration: 03450 - cost: 0.06355 - accuracy: 0.97000\n",
      "Iteration: 03500 - cost: 0.06345 - accuracy: 0.97000\n",
      "Iteration: 03550 - cost: 0.06334 - accuracy: 0.97000\n",
      "Iteration: 03600 - cost: 0.06466 - accuracy: 0.96778\n",
      "Iteration: 03650 - cost: 0.06301 - accuracy: 0.97000\n",
      "Iteration: 03700 - cost: 0.06338 - accuracy: 0.96889\n",
      "Iteration: 03750 - cost: 0.06382 - accuracy: 0.96889\n",
      "Iteration: 03800 - cost: 0.06314 - accuracy: 0.96889\n",
      "Iteration: 03850 - cost: 0.06295 - accuracy: 0.97000\n",
      "Iteration: 03900 - cost: 0.06361 - accuracy: 0.96889\n",
      "Iteration: 03950 - cost: 0.06290 - accuracy: 0.97000\n",
      "Iteration: 04000 - cost: 0.06324 - accuracy: 0.96889\n",
      "Iteration: 04050 - cost: 0.06292 - accuracy: 0.97000\n",
      "Iteration: 04100 - cost: 0.06287 - accuracy: 0.97000\n",
      "Iteration: 04150 - cost: 0.06287 - accuracy: 0.97000\n",
      "Iteration: 04200 - cost: 0.06412 - accuracy: 0.96889\n",
      "Iteration: 04250 - cost: 0.06283 - accuracy: 0.97000\n",
      "Iteration: 04300 - cost: 0.06241 - accuracy: 0.97000\n",
      "Iteration: 04350 - cost: 0.06225 - accuracy: 0.97111\n",
      "Iteration: 04400 - cost: 0.06225 - accuracy: 0.97111\n",
      "Iteration: 04450 - cost: 0.06228 - accuracy: 0.97000\n",
      "Iteration: 04500 - cost: 0.06229 - accuracy: 0.97000\n",
      "Iteration: 04550 - cost: 0.06220 - accuracy: 0.97000\n",
      "Iteration: 04600 - cost: 0.06227 - accuracy: 0.97000\n",
      "Iteration: 04650 - cost: 0.06196 - accuracy: 0.97111\n",
      "Iteration: 04700 - cost: 0.06230 - accuracy: 0.97000\n",
      "Iteration: 04750 - cost: 0.06213 - accuracy: 0.97000\n",
      "Iteration: 04800 - cost: 0.06253 - accuracy: 0.97111\n",
      "Iteration: 04850 - cost: 0.06239 - accuracy: 0.97111\n",
      "Iteration: 04900 - cost: 0.06225 - accuracy: 0.97000\n",
      "Iteration: 04950 - cost: 0.06203 - accuracy: 0.97111\n",
      "Iteration: 05000 - cost: 0.06210 - accuracy: 0.97111\n",
      "Iteration: 05050 - cost: 0.06191 - accuracy: 0.97111\n",
      "Iteration: 05100 - cost: 0.06192 - accuracy: 0.97000\n",
      "Iteration: 05150 - cost: 0.06196 - accuracy: 0.97111\n",
      "Iteration: 05200 - cost: 0.06152 - accuracy: 0.97111\n",
      "Iteration: 05250 - cost: 0.06177 - accuracy: 0.97111\n",
      "Iteration: 05300 - cost: 0.06172 - accuracy: 0.97111\n",
      "Iteration: 05350 - cost: 0.06148 - accuracy: 0.97111\n",
      "Iteration: 05400 - cost: 0.06162 - accuracy: 0.97111\n",
      "Iteration: 05450 - cost: 0.06146 - accuracy: 0.97111\n",
      "Iteration: 05500 - cost: 0.06140 - accuracy: 0.97111\n",
      "Iteration: 05550 - cost: 0.06143 - accuracy: 0.97111\n",
      "Iteration: 05600 - cost: 0.06140 - accuracy: 0.97111\n",
      "Iteration: 05650 - cost: 0.06155 - accuracy: 0.97222\n",
      "Iteration: 05700 - cost: 0.06137 - accuracy: 0.97111\n",
      "Iteration: 05750 - cost: 0.06141 - accuracy: 0.97222\n",
      "Iteration: 05800 - cost: 0.06164 - accuracy: 0.97111\n",
      "Iteration: 05850 - cost: 0.06145 - accuracy: 0.97222\n",
      "Iteration: 05900 - cost: 0.06153 - accuracy: 0.97222\n",
      "Iteration: 05950 - cost: 0.06132 - accuracy: 0.97222\n",
      "Iteration: 06000 - cost: 0.06125 - accuracy: 0.97222\n",
      "Iteration: 06050 - cost: 0.06119 - accuracy: 0.97222\n",
      "Iteration: 06100 - cost: 0.06123 - accuracy: 0.97222\n",
      "Iteration: 06150 - cost: 0.06123 - accuracy: 0.97222\n",
      "Iteration: 06200 - cost: 0.06123 - accuracy: 0.97222\n",
      "Iteration: 06250 - cost: 0.06115 - accuracy: 0.97222\n",
      "Iteration: 06300 - cost: 0.06129 - accuracy: 0.97222\n",
      "Iteration: 06350 - cost: 0.06110 - accuracy: 0.97111\n",
      "Iteration: 06400 - cost: 0.06112 - accuracy: 0.97111\n",
      "Iteration: 06450 - cost: 0.06097 - accuracy: 0.97111\n",
      "Iteration: 06500 - cost: 0.06095 - accuracy: 0.97333\n",
      "Iteration: 06550 - cost: 0.06095 - accuracy: 0.97333\n",
      "Iteration: 06600 - cost: 0.06096 - accuracy: 0.97333\n",
      "Iteration: 06650 - cost: 0.06095 - accuracy: 0.97333\n",
      "Iteration: 06700 - cost: 0.06098 - accuracy: 0.97222\n",
      "Iteration: 06750 - cost: 0.06096 - accuracy: 0.97333\n",
      "Iteration: 06800 - cost: 0.06100 - accuracy: 0.97111\n",
      "Iteration: 06850 - cost: 0.06098 - accuracy: 0.97111\n",
      "Iteration: 06900 - cost: 0.06097 - accuracy: 0.97111\n",
      "Iteration: 06950 - cost: 0.06122 - accuracy: 0.97222\n",
      "Iteration: 07000 - cost: 0.06144 - accuracy: 0.97222\n",
      "Iteration: 07050 - cost: 0.06191 - accuracy: 0.97111\n",
      "Iteration: 07100 - cost: 0.06167 - accuracy: 0.97222\n",
      "Iteration: 07150 - cost: 0.06167 - accuracy: 0.97111\n",
      "Iteration: 07200 - cost: 0.06148 - accuracy: 0.97222\n",
      "Iteration: 07250 - cost: 0.06141 - accuracy: 0.97222\n",
      "Iteration: 07300 - cost: 0.06143 - accuracy: 0.97222\n",
      "Iteration: 07350 - cost: 0.06127 - accuracy: 0.97222\n",
      "Iteration: 07400 - cost: 0.06127 - accuracy: 0.97222\n",
      "Iteration: 07450 - cost: 0.06109 - accuracy: 0.97222\n",
      "Iteration: 07500 - cost: 0.06110 - accuracy: 0.97222\n",
      "Iteration: 07550 - cost: 0.06109 - accuracy: 0.97222\n",
      "Iteration: 07600 - cost: 0.06103 - accuracy: 0.97222\n",
      "Iteration: 07650 - cost: 0.06101 - accuracy: 0.97222\n",
      "Iteration: 07700 - cost: 0.06092 - accuracy: 0.97222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 07750 - cost: 0.06096 - accuracy: 0.97222\n",
      "Iteration: 07800 - cost: 0.06093 - accuracy: 0.97222\n",
      "Iteration: 07850 - cost: 0.06089 - accuracy: 0.97222\n",
      "Iteration: 07900 - cost: 0.06087 - accuracy: 0.97222\n",
      "Iteration: 07950 - cost: 0.06088 - accuracy: 0.97222\n",
      "Iteration: 08000 - cost: 0.06085 - accuracy: 0.97222\n",
      "Iteration: 08050 - cost: 0.06090 - accuracy: 0.97222\n",
      "Iteration: 08100 - cost: 0.06089 - accuracy: 0.97222\n",
      "Iteration: 08150 - cost: 0.06073 - accuracy: 0.97222\n",
      "Iteration: 08200 - cost: 0.06089 - accuracy: 0.97222\n",
      "Iteration: 08250 - cost: 0.06090 - accuracy: 0.97222\n",
      "Iteration: 08300 - cost: 0.06071 - accuracy: 0.97222\n",
      "Iteration: 08350 - cost: 0.06069 - accuracy: 0.97222\n",
      "Iteration: 08400 - cost: 0.06073 - accuracy: 0.97222\n",
      "Iteration: 08450 - cost: 0.06080 - accuracy: 0.97222\n",
      "Iteration: 08500 - cost: 0.06071 - accuracy: 0.97222\n",
      "Iteration: 08550 - cost: 0.06067 - accuracy: 0.97222\n",
      "Iteration: 08600 - cost: 0.06067 - accuracy: 0.97222\n",
      "Iteration: 08650 - cost: 0.06074 - accuracy: 0.97222\n",
      "Iteration: 08700 - cost: 0.06071 - accuracy: 0.97222\n",
      "Iteration: 08750 - cost: 0.06072 - accuracy: 0.97222\n",
      "Iteration: 08800 - cost: 0.06060 - accuracy: 0.97222\n",
      "Iteration: 08850 - cost: 0.06055 - accuracy: 0.97222\n",
      "Iteration: 08900 - cost: 0.06073 - accuracy: 0.97222\n",
      "Iteration: 08950 - cost: 0.06055 - accuracy: 0.97222\n",
      "Iteration: 09000 - cost: 0.06060 - accuracy: 0.97222\n",
      "Iteration: 09050 - cost: 0.06079 - accuracy: 0.97222\n",
      "Iteration: 09100 - cost: 0.06070 - accuracy: 0.97222\n",
      "Iteration: 09150 - cost: 0.06055 - accuracy: 0.97222\n",
      "Iteration: 09200 - cost: 0.06047 - accuracy: 0.97222\n",
      "Iteration: 09250 - cost: 0.06062 - accuracy: 0.97222\n",
      "Iteration: 09300 - cost: 0.06062 - accuracy: 0.97222\n",
      "Iteration: 09350 - cost: 0.06046 - accuracy: 0.97111\n",
      "Iteration: 09400 - cost: 0.06055 - accuracy: 0.97222\n",
      "Iteration: 09450 - cost: 0.06057 - accuracy: 0.97222\n",
      "Iteration: 09500 - cost: 0.06052 - accuracy: 0.97222\n",
      "Iteration: 09550 - cost: 0.06055 - accuracy: 0.97222\n",
      "Iteration: 09600 - cost: 0.06043 - accuracy: 0.97222\n",
      "Iteration: 09650 - cost: 0.06050 - accuracy: 0.97222\n",
      "Iteration: 09700 - cost: 0.06052 - accuracy: 0.97222\n",
      "Iteration: 09750 - cost: 0.06037 - accuracy: 0.97111\n",
      "Iteration: 09800 - cost: 0.06049 - accuracy: 0.97222\n",
      "Iteration: 09850 - cost: 0.06058 - accuracy: 0.97222\n",
      "Iteration: 09900 - cost: 0.06045 - accuracy: 0.97222\n",
      "Iteration: 09950 - cost: 0.06032 - accuracy: 0.97222\n"
     ]
    }
   ],
   "source": [
    "hist = nn.train(X_train.T, y_train.reshape(1, y_train.shape[0]), 10000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, _ = nn.predict(X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementarea aceleiasi arhitecturi folosind Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(2)),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 25)                75        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 2s 124ms/step - loss: 0.6885 - accuracy: 0.5218 - val_loss: 0.6860 - val_accuracy: 0.6600\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.7071 - val_loss: 0.6824 - val_accuracy: 0.7600\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.8261 - val_loss: 0.6788 - val_accuracy: 0.7300\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6742 - accuracy: 0.8176 - val_loss: 0.6761 - val_accuracy: 0.7300\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6709 - accuracy: 0.8179 - val_loss: 0.6728 - val_accuracy: 0.8200\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6684 - accuracy: 0.8374 - val_loss: 0.6700 - val_accuracy: 0.8100\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6645 - accuracy: 0.8296 - val_loss: 0.6667 - val_accuracy: 0.8200\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6598 - accuracy: 0.8521 - val_loss: 0.6636 - val_accuracy: 0.8200\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.6568 - accuracy: 0.8556 - val_loss: 0.6608 - val_accuracy: 0.8100\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6515 - accuracy: 0.8586 - val_loss: 0.6579 - val_accuracy: 0.8100\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6502 - accuracy: 0.8361 - val_loss: 0.6558 - val_accuracy: 0.8100\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6469 - accuracy: 0.8280 - val_loss: 0.6528 - val_accuracy: 0.8100\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6438 - accuracy: 0.8263 - val_loss: 0.6500 - val_accuracy: 0.8100\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6398 - accuracy: 0.8293 - val_loss: 0.6472 - val_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6360 - accuracy: 0.8265 - val_loss: 0.6436 - val_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6326 - accuracy: 0.8230 - val_loss: 0.6409 - val_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6280 - accuracy: 0.8312 - val_loss: 0.6380 - val_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6249 - accuracy: 0.8285 - val_loss: 0.6344 - val_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6211 - accuracy: 0.8301 - val_loss: 0.6315 - val_accuracy: 0.8100\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6182 - accuracy: 0.8286 - val_loss: 0.6278 - val_accuracy: 0.8100\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6129 - accuracy: 0.8410 - val_loss: 0.6242 - val_accuracy: 0.8100\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6125 - accuracy: 0.8068 - val_loss: 0.6208 - val_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6038 - accuracy: 0.8266 - val_loss: 0.6181 - val_accuracy: 0.7900\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5998 - accuracy: 0.8243 - val_loss: 0.6137 - val_accuracy: 0.7900\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5966 - accuracy: 0.8164 - val_loss: 0.6100 - val_accuracy: 0.7900\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5897 - accuracy: 0.8321 - val_loss: 0.6052 - val_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5839 - accuracy: 0.8295 - val_loss: 0.6013 - val_accuracy: 0.8000\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5829 - accuracy: 0.8201 - val_loss: 0.5970 - val_accuracy: 0.8000\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5781 - accuracy: 0.8258 - val_loss: 0.5924 - val_accuracy: 0.8000\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5716 - accuracy: 0.8316 - val_loss: 0.5877 - val_accuracy: 0.8000\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5656 - accuracy: 0.8317 - val_loss: 0.5834 - val_accuracy: 0.8100\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5648 - accuracy: 0.8087 - val_loss: 0.5791 - val_accuracy: 0.8000\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5555 - accuracy: 0.8326 - val_loss: 0.5742 - val_accuracy: 0.8100\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5488 - accuracy: 0.8230 - val_loss: 0.5689 - val_accuracy: 0.8000\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5445 - accuracy: 0.8291 - val_loss: 0.5636 - val_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5379 - accuracy: 0.8269 - val_loss: 0.5581 - val_accuracy: 0.8000\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5282 - accuracy: 0.8378 - val_loss: 0.5528 - val_accuracy: 0.8100\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5249 - accuracy: 0.8370 - val_loss: 0.5483 - val_accuracy: 0.8100\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5130 - accuracy: 0.8363 - val_loss: 0.5422 - val_accuracy: 0.8100\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5121 - accuracy: 0.8192 - val_loss: 0.5362 - val_accuracy: 0.8100\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5043 - accuracy: 0.8210 - val_loss: 0.5300 - val_accuracy: 0.8100\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4980 - accuracy: 0.8249 - val_loss: 0.5247 - val_accuracy: 0.8100\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4921 - accuracy: 0.8226 - val_loss: 0.5180 - val_accuracy: 0.8100\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4825 - accuracy: 0.8249 - val_loss: 0.5121 - val_accuracy: 0.8100\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4813 - accuracy: 0.8140 - val_loss: 0.5048 - val_accuracy: 0.8100\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4654 - accuracy: 0.8344 - val_loss: 0.4989 - val_accuracy: 0.8200\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4578 - accuracy: 0.8358 - val_loss: 0.4938 - val_accuracy: 0.8100\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4626 - accuracy: 0.8192 - val_loss: 0.4878 - val_accuracy: 0.8100\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.4437 - accuracy: 0.8332 - val_loss: 0.4834 - val_accuracy: 0.8100\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4381 - accuracy: 0.8365 - val_loss: 0.4778 - val_accuracy: 0.8100\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4366 - accuracy: 0.8324 - val_loss: 0.4714 - val_accuracy: 0.8200\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4279 - accuracy: 0.8347 - val_loss: 0.4681 - val_accuracy: 0.8100\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4141 - accuracy: 0.8391 - val_loss: 0.4649 - val_accuracy: 0.8100\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4175 - accuracy: 0.8317 - val_loss: 0.4583 - val_accuracy: 0.8100\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4144 - accuracy: 0.8297 - val_loss: 0.4537 - val_accuracy: 0.8100\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4040 - accuracy: 0.8364 - val_loss: 0.4474 - val_accuracy: 0.8200\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3965 - accuracy: 0.8419 - val_loss: 0.4449 - val_accuracy: 0.8200\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4036 - accuracy: 0.8321 - val_loss: 0.4407 - val_accuracy: 0.8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3982 - accuracy: 0.8366 - val_loss: 0.4390 - val_accuracy: 0.8100\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3883 - accuracy: 0.8355 - val_loss: 0.4314 - val_accuracy: 0.8200\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3965 - accuracy: 0.8261 - val_loss: 0.4279 - val_accuracy: 0.8200\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3804 - accuracy: 0.8430 - val_loss: 0.4234 - val_accuracy: 0.8200\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3668 - accuracy: 0.8450 - val_loss: 0.4159 - val_accuracy: 0.8200\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3823 - accuracy: 0.8429 - val_loss: 0.4140 - val_accuracy: 0.8200\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3793 - accuracy: 0.8393 - val_loss: 0.4118 - val_accuracy: 0.8200\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3558 - accuracy: 0.8492 - val_loss: 0.4087 - val_accuracy: 0.8200\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3502 - accuracy: 0.8558 - val_loss: 0.4044 - val_accuracy: 0.8200\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3610 - accuracy: 0.8415 - val_loss: 0.4017 - val_accuracy: 0.8200\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3534 - accuracy: 0.8536 - val_loss: 0.3957 - val_accuracy: 0.8200\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3426 - accuracy: 0.8502 - val_loss: 0.3922 - val_accuracy: 0.8200\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3463 - accuracy: 0.8435 - val_loss: 0.3871 - val_accuracy: 0.8200\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3469 - accuracy: 0.8551 - val_loss: 0.3844 - val_accuracy: 0.8200\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3478 - accuracy: 0.8462 - val_loss: 0.3830 - val_accuracy: 0.8200\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3435 - accuracy: 0.8457 - val_loss: 0.3844 - val_accuracy: 0.8200\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3402 - accuracy: 0.8488 - val_loss: 0.3780 - val_accuracy: 0.8200\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3157 - accuracy: 0.8675 - val_loss: 0.3739 - val_accuracy: 0.8200\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3300 - accuracy: 0.8596 - val_loss: 0.3711 - val_accuracy: 0.8200\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3325 - accuracy: 0.8538 - val_loss: 0.3686 - val_accuracy: 0.8200\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3322 - accuracy: 0.8530 - val_loss: 0.3713 - val_accuracy: 0.8200\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3387 - accuracy: 0.8504 - val_loss: 0.3697 - val_accuracy: 0.8200\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.3301 - accuracy: 0.8478 - val_loss: 0.3694 - val_accuracy: 0.8200\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3243 - accuracy: 0.8615 - val_loss: 0.3640 - val_accuracy: 0.8200\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3155 - accuracy: 0.8602 - val_loss: 0.3625 - val_accuracy: 0.8200\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3364 - accuracy: 0.8499 - val_loss: 0.3594 - val_accuracy: 0.8200\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3140 - accuracy: 0.8644 - val_loss: 0.3530 - val_accuracy: 0.8300\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3167 - accuracy: 0.8609 - val_loss: 0.3526 - val_accuracy: 0.8200\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3085 - accuracy: 0.8635 - val_loss: 0.3514 - val_accuracy: 0.8200\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2925 - accuracy: 0.8774 - val_loss: 0.3495 - val_accuracy: 0.8200\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3115 - accuracy: 0.8544 - val_loss: 0.3471 - val_accuracy: 0.8200\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3155 - accuracy: 0.8638 - val_loss: 0.3431 - val_accuracy: 0.8300\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3305 - accuracy: 0.8426 - val_loss: 0.3420 - val_accuracy: 0.8300\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3101 - accuracy: 0.8571 - val_loss: 0.3411 - val_accuracy: 0.8200\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3020 - accuracy: 0.8685 - val_loss: 0.3394 - val_accuracy: 0.8200\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2939 - accuracy: 0.8662 - val_loss: 0.3377 - val_accuracy: 0.8200\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2989 - accuracy: 0.8671 - val_loss: 0.3351 - val_accuracy: 0.8300\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3113 - accuracy: 0.8549 - val_loss: 0.3393 - val_accuracy: 0.8300\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3154 - accuracy: 0.8583 - val_loss: 0.3395 - val_accuracy: 0.8300\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2868 - accuracy: 0.8743 - val_loss: 0.3296 - val_accuracy: 0.8300\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2794 - accuracy: 0.8762 - val_loss: 0.3270 - val_accuracy: 0.8400\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2927 - accuracy: 0.8721 - val_loss: 0.3258 - val_accuracy: 0.8400\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2950 - accuracy: 0.8638 - val_loss: 0.3235 - val_accuracy: 0.8500\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3119 - accuracy: 0.8603 - val_loss: 0.3287 - val_accuracy: 0.8300\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2960 - accuracy: 0.8694 - val_loss: 0.3253 - val_accuracy: 0.8400\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2792 - accuracy: 0.8750 - val_loss: 0.3281 - val_accuracy: 0.8400\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3008 - accuracy: 0.8604 - val_loss: 0.3257 - val_accuracy: 0.8300\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3085 - accuracy: 0.8576 - val_loss: 0.3206 - val_accuracy: 0.8400\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2734 - accuracy: 0.8818 - val_loss: 0.3157 - val_accuracy: 0.8500\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2814 - accuracy: 0.8774 - val_loss: 0.3149 - val_accuracy: 0.8500\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2764 - accuracy: 0.8756 - val_loss: 0.3145 - val_accuracy: 0.8600\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2846 - accuracy: 0.8773 - val_loss: 0.3120 - val_accuracy: 0.8400\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2842 - accuracy: 0.8847 - val_loss: 0.3112 - val_accuracy: 0.8500\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2841 - accuracy: 0.8738 - val_loss: 0.3097 - val_accuracy: 0.8400\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2815 - accuracy: 0.8835 - val_loss: 0.3115 - val_accuracy: 0.8500\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2653 - accuracy: 0.8803 - val_loss: 0.3078 - val_accuracy: 0.8400\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2713 - accuracy: 0.8792 - val_loss: 0.3066 - val_accuracy: 0.8600\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2879 - accuracy: 0.8720 - val_loss: 0.3067 - val_accuracy: 0.8500\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2696 - accuracy: 0.8823 - val_loss: 0.3051 - val_accuracy: 0.8600\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2904 - accuracy: 0.8636 - val_loss: 0.3036 - val_accuracy: 0.8600\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2773 - accuracy: 0.8803 - val_loss: 0.3059 - val_accuracy: 0.8500\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2745 - accuracy: 0.8746 - val_loss: 0.3015 - val_accuracy: 0.8500\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.2744 - accuracy: 0.8830 - val_loss: 0.3055 - val_accuracy: 0.8600\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2808 - accuracy: 0.8695 - val_loss: 0.3035 - val_accuracy: 0.8500\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2624 - accuracy: 0.8852 - val_loss: 0.2986 - val_accuracy: 0.8500\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2702 - accuracy: 0.8826 - val_loss: 0.3045 - val_accuracy: 0.8600\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2573 - accuracy: 0.8862 - val_loss: 0.3035 - val_accuracy: 0.8600\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2731 - accuracy: 0.8774 - val_loss: 0.3016 - val_accuracy: 0.8600\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2676 - accuracy: 0.8797 - val_loss: 0.3034 - val_accuracy: 0.8500\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2584 - accuracy: 0.8818 - val_loss: 0.3098 - val_accuracy: 0.8400\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2756 - accuracy: 0.8749 - val_loss: 0.2942 - val_accuracy: 0.8500\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2628 - accuracy: 0.8892 - val_loss: 0.2993 - val_accuracy: 0.8600\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2634 - accuracy: 0.8768 - val_loss: 0.2980 - val_accuracy: 0.8600\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2587 - accuracy: 0.8828 - val_loss: 0.2965 - val_accuracy: 0.8600\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2592 - accuracy: 0.8848 - val_loss: 0.2985 - val_accuracy: 0.8600\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2587 - accuracy: 0.8865 - val_loss: 0.2957 - val_accuracy: 0.8600\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2579 - accuracy: 0.8909 - val_loss: 0.2999 - val_accuracy: 0.8500\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2633 - accuracy: 0.8862 - val_loss: 0.2948 - val_accuracy: 0.8600\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2517 - accuracy: 0.8851 - val_loss: 0.2938 - val_accuracy: 0.8600\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2544 - accuracy: 0.8876 - val_loss: 0.2882 - val_accuracy: 0.8400\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2478 - accuracy: 0.8880 - val_loss: 0.2851 - val_accuracy: 0.8400\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2581 - accuracy: 0.8948 - val_loss: 0.2854 - val_accuracy: 0.8500\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2439 - accuracy: 0.8856 - val_loss: 0.2975 - val_accuracy: 0.8500\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2611 - accuracy: 0.8880 - val_loss: 0.2922 - val_accuracy: 0.8600\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2513 - accuracy: 0.8873 - val_loss: 0.2925 - val_accuracy: 0.8600\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2443 - accuracy: 0.8947 - val_loss: 0.2867 - val_accuracy: 0.8500\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2572 - accuracy: 0.8813 - val_loss: 0.2887 - val_accuracy: 0.8600\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2551 - accuracy: 0.8866 - val_loss: 0.2917 - val_accuracy: 0.8700\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2622 - accuracy: 0.8828 - val_loss: 0.2848 - val_accuracy: 0.8500\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2489 - accuracy: 0.8863 - val_loss: 0.2874 - val_accuracy: 0.8600\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2543 - accuracy: 0.8883 - val_loss: 0.2780 - val_accuracy: 0.8400\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2624 - accuracy: 0.8857 - val_loss: 0.2776 - val_accuracy: 0.8400\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2439 - accuracy: 0.8896 - val_loss: 0.2777 - val_accuracy: 0.8500\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2407 - accuracy: 0.9020 - val_loss: 0.2784 - val_accuracy: 0.8500\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2447 - accuracy: 0.8811 - val_loss: 0.2812 - val_accuracy: 0.8600\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.2612 - accuracy: 0.8807 - val_loss: 0.2786 - val_accuracy: 0.8600\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2447 - accuracy: 0.8916 - val_loss: 0.2838 - val_accuracy: 0.8600\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2420 - accuracy: 0.8873 - val_loss: 0.2927 - val_accuracy: 0.8400\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2426 - accuracy: 0.9029 - val_loss: 0.2835 - val_accuracy: 0.8700\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2444 - accuracy: 0.8871 - val_loss: 0.2825 - val_accuracy: 0.8500\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2408 - accuracy: 0.8947 - val_loss: 0.2742 - val_accuracy: 0.8600\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2430 - accuracy: 0.8858 - val_loss: 0.2715 - val_accuracy: 0.8600\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2415 - accuracy: 0.8952 - val_loss: 0.2726 - val_accuracy: 0.8600\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2444 - accuracy: 0.8907 - val_loss: 0.2710 - val_accuracy: 0.8700\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2199 - accuracy: 0.9053 - val_loss: 0.2704 - val_accuracy: 0.8600\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2280 - accuracy: 0.8961 - val_loss: 0.2749 - val_accuracy: 0.8500\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2503 - accuracy: 0.8857 - val_loss: 0.2722 - val_accuracy: 0.8500\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2296 - accuracy: 0.8941 - val_loss: 0.2708 - val_accuracy: 0.8600\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2513 - accuracy: 0.8840 - val_loss: 0.2698 - val_accuracy: 0.8600\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2328 - accuracy: 0.8888 - val_loss: 0.2647 - val_accuracy: 0.8500\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2380 - accuracy: 0.8909 - val_loss: 0.2660 - val_accuracy: 0.8600\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2451 - accuracy: 0.8966 - val_loss: 0.2635 - val_accuracy: 0.8600\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2379 - accuracy: 0.8960 - val_loss: 0.2676 - val_accuracy: 0.8600\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2349 - accuracy: 0.8930 - val_loss: 0.2634 - val_accuracy: 0.8600\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2338 - accuracy: 0.8913 - val_loss: 0.2629 - val_accuracy: 0.8600\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2257 - accuracy: 0.9059 - val_loss: 0.2677 - val_accuracy: 0.8600\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2276 - accuracy: 0.8998 - val_loss: 0.2675 - val_accuracy: 0.8500\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2362 - accuracy: 0.9002 - val_loss: 0.2605 - val_accuracy: 0.8600\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2351 - accuracy: 0.8928 - val_loss: 0.2620 - val_accuracy: 0.8700\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2376 - accuracy: 0.9048 - val_loss: 0.2577 - val_accuracy: 0.8600\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2377 - accuracy: 0.8952 - val_loss: 0.2562 - val_accuracy: 0.8600\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2250 - accuracy: 0.8950 - val_loss: 0.2560 - val_accuracy: 0.8700\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2276 - accuracy: 0.9033 - val_loss: 0.2572 - val_accuracy: 0.8600\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2232 - accuracy: 0.8982 - val_loss: 0.2555 - val_accuracy: 0.8600\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2295 - accuracy: 0.9020 - val_loss: 0.2525 - val_accuracy: 0.8600\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2260 - accuracy: 0.8986 - val_loss: 0.2529 - val_accuracy: 0.8700\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2158 - accuracy: 0.9145 - val_loss: 0.2530 - val_accuracy: 0.8700\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1907 - accuracy: 0.9248 - val_loss: 0.2516 - val_accuracy: 0.8600\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2207 - accuracy: 0.9083 - val_loss: 0.2530 - val_accuracy: 0.8700\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2393 - accuracy: 0.8974 - val_loss: 0.2533 - val_accuracy: 0.8700\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2295 - accuracy: 0.8976 - val_loss: 0.2507 - val_accuracy: 0.8700\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2256 - accuracy: 0.9001 - val_loss: 0.2585 - val_accuracy: 0.8600\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2190 - accuracy: 0.9044 - val_loss: 0.2588 - val_accuracy: 0.8700\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2467 - accuracy: 0.8872 - val_loss: 0.2621 - val_accuracy: 0.8800\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.2245 - accuracy: 0.8986 - val_loss: 0.2522 - val_accuracy: 0.8700\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2113 - accuracy: 0.9084 - val_loss: 0.2463 - val_accuracy: 0.8700\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2167 - accuracy: 0.9045 - val_loss: 0.2580 - val_accuracy: 0.8800\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2175 - accuracy: 0.9044 - val_loss: 0.2501 - val_accuracy: 0.8700\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2087 - accuracy: 0.9142 - val_loss: 0.2462 - val_accuracy: 0.8700\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2377 - accuracy: 0.8976 - val_loss: 0.2432 - val_accuracy: 0.8700\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2149 - accuracy: 0.9066 - val_loss: 0.2416 - val_accuracy: 0.8800\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2086 - accuracy: 0.9096 - val_loss: 0.2443 - val_accuracy: 0.8700\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2178 - accuracy: 0.9082 - val_loss: 0.2484 - val_accuracy: 0.8800\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2065 - accuracy: 0.9154 - val_loss: 0.2432 - val_accuracy: 0.8700\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2070 - accuracy: 0.9156 - val_loss: 0.2410 - val_accuracy: 0.8700\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2124 - accuracy: 0.9052 - val_loss: 0.2391 - val_accuracy: 0.8700\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2125 - accuracy: 0.9124 - val_loss: 0.2430 - val_accuracy: 0.8800\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2019 - accuracy: 0.9128 - val_loss: 0.2602 - val_accuracy: 0.8800\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2265 - accuracy: 0.9009 - val_loss: 0.2384 - val_accuracy: 0.8700\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2153 - accuracy: 0.9119 - val_loss: 0.2368 - val_accuracy: 0.8800\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1986 - accuracy: 0.9222 - val_loss: 0.2335 - val_accuracy: 0.8800\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2055 - accuracy: 0.9176 - val_loss: 0.2331 - val_accuracy: 0.8900\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2031 - accuracy: 0.9141 - val_loss: 0.2332 - val_accuracy: 0.8800\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2027 - accuracy: 0.9132 - val_loss: 0.2309 - val_accuracy: 0.8800\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1974 - accuracy: 0.9246 - val_loss: 0.2347 - val_accuracy: 0.8700\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2181 - accuracy: 0.9013 - val_loss: 0.2317 - val_accuracy: 0.8800\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2104 - accuracy: 0.9106 - val_loss: 0.2366 - val_accuracy: 0.8800\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2061 - accuracy: 0.9163 - val_loss: 0.2310 - val_accuracy: 0.8800\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1944 - accuracy: 0.9209 - val_loss: 0.2313 - val_accuracy: 0.8900\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2083 - accuracy: 0.9122 - val_loss: 0.2251 - val_accuracy: 0.8800\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2030 - accuracy: 0.9146 - val_loss: 0.2305 - val_accuracy: 0.8900\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2185 - accuracy: 0.9100 - val_loss: 0.2237 - val_accuracy: 0.8800\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1871 - accuracy: 0.9177 - val_loss: 0.2259 - val_accuracy: 0.8800\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2095 - accuracy: 0.9078 - val_loss: 0.2221 - val_accuracy: 0.8700\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2064 - accuracy: 0.9102 - val_loss: 0.2218 - val_accuracy: 0.8800\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2057 - accuracy: 0.9115 - val_loss: 0.2205 - val_accuracy: 0.8800\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2032 - accuracy: 0.9128 - val_loss: 0.2222 - val_accuracy: 0.8900\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.1943 - accuracy: 0.9208 - val_loss: 0.2223 - val_accuracy: 0.8900\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1961 - accuracy: 0.9196 - val_loss: 0.2301 - val_accuracy: 0.8800\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1920 - accuracy: 0.9239 - val_loss: 0.2174 - val_accuracy: 0.8700\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1961 - accuracy: 0.9135 - val_loss: 0.2164 - val_accuracy: 0.8700\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2093 - accuracy: 0.9081 - val_loss: 0.2196 - val_accuracy: 0.9000\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2001 - accuracy: 0.9186 - val_loss: 0.2251 - val_accuracy: 0.8800\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1981 - accuracy: 0.9209 - val_loss: 0.2240 - val_accuracy: 0.8900\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1749 - accuracy: 0.9340 - val_loss: 0.2142 - val_accuracy: 0.8900\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2021 - accuracy: 0.9190 - val_loss: 0.2138 - val_accuracy: 0.8900\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1903 - accuracy: 0.9218 - val_loss: 0.2259 - val_accuracy: 0.8900\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1907 - accuracy: 0.9174 - val_loss: 0.2172 - val_accuracy: 0.8900\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1903 - accuracy: 0.9231 - val_loss: 0.2142 - val_accuracy: 0.8900\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1745 - accuracy: 0.9281 - val_loss: 0.2122 - val_accuracy: 0.8900\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1687 - accuracy: 0.9320 - val_loss: 0.2093 - val_accuracy: 0.8800\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1857 - accuracy: 0.9212 - val_loss: 0.2085 - val_accuracy: 0.8900\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2050 - accuracy: 0.9185 - val_loss: 0.2078 - val_accuracy: 0.8900\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1668 - accuracy: 0.9359 - val_loss: 0.2079 - val_accuracy: 0.9000\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1792 - accuracy: 0.9308 - val_loss: 0.2093 - val_accuracy: 0.9000\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1839 - accuracy: 0.9257 - val_loss: 0.2087 - val_accuracy: 0.9000\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1971 - accuracy: 0.9178 - val_loss: 0.2075 - val_accuracy: 0.9000\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1862 - accuracy: 0.9255 - val_loss: 0.2100 - val_accuracy: 0.9000\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1876 - accuracy: 0.9235 - val_loss: 0.2070 - val_accuracy: 0.9000\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1777 - accuracy: 0.9325 - val_loss: 0.2013 - val_accuracy: 0.8800\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1806 - accuracy: 0.9289 - val_loss: 0.2115 - val_accuracy: 0.9100\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1886 - accuracy: 0.9221 - val_loss: 0.2091 - val_accuracy: 0.9000\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1872 - accuracy: 0.9225 - val_loss: 0.2028 - val_accuracy: 0.9000\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1889 - accuracy: 0.9237 - val_loss: 0.1992 - val_accuracy: 0.8800\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1766 - accuracy: 0.9251 - val_loss: 0.2070 - val_accuracy: 0.9100\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1783 - accuracy: 0.9281 - val_loss: 0.1999 - val_accuracy: 0.9000\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1782 - accuracy: 0.9266 - val_loss: 0.1976 - val_accuracy: 0.9000\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1753 - accuracy: 0.9337 - val_loss: 0.1981 - val_accuracy: 0.9000\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1700 - accuracy: 0.9324 - val_loss: 0.2003 - val_accuracy: 0.9000\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1748 - accuracy: 0.9330 - val_loss: 0.1974 - val_accuracy: 0.9000\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1771 - accuracy: 0.9233 - val_loss: 0.1943 - val_accuracy: 0.9000\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1816 - accuracy: 0.9271 - val_loss: 0.1994 - val_accuracy: 0.9100\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1655 - accuracy: 0.9372 - val_loss: 0.1914 - val_accuracy: 0.9000\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1686 - accuracy: 0.9335 - val_loss: 0.1959 - val_accuracy: 0.9100\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1763 - accuracy: 0.9353 - val_loss: 0.1891 - val_accuracy: 0.8900\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1737 - accuracy: 0.9253 - val_loss: 0.1886 - val_accuracy: 0.9000\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1697 - accuracy: 0.9329 - val_loss: 0.2000 - val_accuracy: 0.9300\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.1642 - accuracy: 0.9364 - val_loss: 0.1894 - val_accuracy: 0.9000\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1698 - accuracy: 0.9342 - val_loss: 0.1928 - val_accuracy: 0.9200\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1616 - accuracy: 0.9468 - val_loss: 0.1904 - val_accuracy: 0.9200\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1555 - accuracy: 0.9384 - val_loss: 0.1844 - val_accuracy: 0.9000\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1593 - accuracy: 0.9364 - val_loss: 0.1823 - val_accuracy: 0.9100\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1666 - accuracy: 0.9372 - val_loss: 0.1845 - val_accuracy: 0.9000\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1694 - accuracy: 0.9292 - val_loss: 0.1823 - val_accuracy: 0.9000\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1591 - accuracy: 0.9342 - val_loss: 0.1802 - val_accuracy: 0.9000\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1656 - accuracy: 0.9384 - val_loss: 0.1846 - val_accuracy: 0.9100\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1657 - accuracy: 0.9397 - val_loss: 0.1905 - val_accuracy: 0.9400\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1700 - accuracy: 0.9354 - val_loss: 0.1827 - val_accuracy: 0.9200\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1700 - accuracy: 0.9354 - val_loss: 0.1762 - val_accuracy: 0.9100\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1724 - accuracy: 0.9277 - val_loss: 0.1760 - val_accuracy: 0.9100\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1599 - accuracy: 0.9365 - val_loss: 0.1762 - val_accuracy: 0.9100\n",
      "Epoch 280/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1501 - accuracy: 0.9410 - val_loss: 0.1745 - val_accuracy: 0.9000\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1590 - accuracy: 0.9322 - val_loss: 0.1732 - val_accuracy: 0.9100\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1482 - accuracy: 0.9423 - val_loss: 0.1742 - val_accuracy: 0.9100\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1409 - accuracy: 0.9456 - val_loss: 0.1716 - val_accuracy: 0.9100\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1505 - accuracy: 0.9363 - val_loss: 0.1699 - val_accuracy: 0.9200\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1609 - accuracy: 0.9357 - val_loss: 0.1844 - val_accuracy: 0.9400\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1558 - accuracy: 0.9402 - val_loss: 0.1745 - val_accuracy: 0.9300\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1590 - accuracy: 0.9313 - val_loss: 0.1702 - val_accuracy: 0.9200\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1493 - accuracy: 0.9430 - val_loss: 0.1830 - val_accuracy: 0.9300\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1571 - accuracy: 0.9365 - val_loss: 0.1783 - val_accuracy: 0.9300\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1397 - accuracy: 0.9472 - val_loss: 0.1650 - val_accuracy: 0.9200\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1499 - accuracy: 0.9441 - val_loss: 0.1665 - val_accuracy: 0.9100\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1512 - accuracy: 0.9416 - val_loss: 0.1708 - val_accuracy: 0.9300\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1534 - accuracy: 0.9382 - val_loss: 0.1625 - val_accuracy: 0.9100\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1327 - accuracy: 0.9525 - val_loss: 0.1629 - val_accuracy: 0.9300\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1538 - accuracy: 0.9409 - val_loss: 0.1599 - val_accuracy: 0.9200\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1580 - accuracy: 0.9414 - val_loss: 0.1611 - val_accuracy: 0.9300\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1513 - accuracy: 0.9390 - val_loss: 0.1836 - val_accuracy: 0.9400\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1427 - accuracy: 0.9450 - val_loss: 0.1779 - val_accuracy: 0.9400\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1434 - accuracy: 0.9500 - val_loss: 0.1679 - val_accuracy: 0.9400\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1551 - accuracy: 0.9441 - val_loss: 0.1609 - val_accuracy: 0.9500\n",
      "Epoch 301/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1487 - accuracy: 0.9372 - val_loss: 0.1577 - val_accuracy: 0.9400\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1407 - accuracy: 0.9423 - val_loss: 0.1616 - val_accuracy: 0.9400\n",
      "Epoch 303/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1476 - accuracy: 0.9369 - val_loss: 0.1644 - val_accuracy: 0.9400\n",
      "Epoch 304/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1369 - accuracy: 0.9446 - val_loss: 0.1564 - val_accuracy: 0.9400\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1465 - accuracy: 0.9411 - val_loss: 0.1574 - val_accuracy: 0.9400\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.1452 - accuracy: 0.9402 - val_loss: 0.1536 - val_accuracy: 0.9400\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1529 - accuracy: 0.9330 - val_loss: 0.1502 - val_accuracy: 0.9300\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1417 - accuracy: 0.9453 - val_loss: 0.1505 - val_accuracy: 0.9400\n",
      "Epoch 309/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1415 - accuracy: 0.9443 - val_loss: 0.1511 - val_accuracy: 0.9500\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1392 - accuracy: 0.9430 - val_loss: 0.1494 - val_accuracy: 0.9400\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1367 - accuracy: 0.9541 - val_loss: 0.1463 - val_accuracy: 0.9300\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1400 - accuracy: 0.9471 - val_loss: 0.1496 - val_accuracy: 0.9500\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1373 - accuracy: 0.9487 - val_loss: 0.1463 - val_accuracy: 0.9500\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1480 - accuracy: 0.9401 - val_loss: 0.1448 - val_accuracy: 0.9500\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1420 - accuracy: 0.9432 - val_loss: 0.1451 - val_accuracy: 0.9500\n",
      "Epoch 316/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1290 - accuracy: 0.9484 - val_loss: 0.1435 - val_accuracy: 0.9600\n",
      "Epoch 317/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1295 - accuracy: 0.9488 - val_loss: 0.1444 - val_accuracy: 0.9500\n",
      "Epoch 318/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1372 - accuracy: 0.9486 - val_loss: 0.1518 - val_accuracy: 0.9500\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1328 - accuracy: 0.9466 - val_loss: 0.1457 - val_accuracy: 0.9500\n",
      "Epoch 320/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1340 - accuracy: 0.9434 - val_loss: 0.1506 - val_accuracy: 0.9500\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1427 - accuracy: 0.9393 - val_loss: 0.1494 - val_accuracy: 0.9500\n",
      "Epoch 322/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1358 - accuracy: 0.9474 - val_loss: 0.1419 - val_accuracy: 0.9500\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1392 - accuracy: 0.9431 - val_loss: 0.1397 - val_accuracy: 0.9500\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1331 - accuracy: 0.9470 - val_loss: 0.1398 - val_accuracy: 0.9500\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1344 - accuracy: 0.9438 - val_loss: 0.1389 - val_accuracy: 0.9500\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1378 - accuracy: 0.9460 - val_loss: 0.1388 - val_accuracy: 0.9500\n",
      "Epoch 327/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1277 - accuracy: 0.9479 - val_loss: 0.1334 - val_accuracy: 0.9400\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1268 - accuracy: 0.9548 - val_loss: 0.1558 - val_accuracy: 0.9500\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1455 - accuracy: 0.9490 - val_loss: 0.1329 - val_accuracy: 0.9500\n",
      "Epoch 330/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1264 - accuracy: 0.9563 - val_loss: 0.1331 - val_accuracy: 0.9500\n",
      "Epoch 331/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1367 - accuracy: 0.9473 - val_loss: 0.1311 - val_accuracy: 0.9600\n",
      "Epoch 332/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1350 - accuracy: 0.9487 - val_loss: 0.1378 - val_accuracy: 0.9500\n",
      "Epoch 333/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1323 - accuracy: 0.9508 - val_loss: 0.1411 - val_accuracy: 0.9500\n",
      "Epoch 334/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1330 - accuracy: 0.9462 - val_loss: 0.1287 - val_accuracy: 0.9600\n",
      "Epoch 335/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1352 - accuracy: 0.9486 - val_loss: 0.1290 - val_accuracy: 0.9600\n",
      "Epoch 336/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1250 - accuracy: 0.9496 - val_loss: 0.1271 - val_accuracy: 0.9600\n",
      "Epoch 337/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1206 - accuracy: 0.9527 - val_loss: 0.1270 - val_accuracy: 0.9300\n",
      "Epoch 338/1000\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.1241 - accuracy: 0.9567 - val_loss: 0.1256 - val_accuracy: 0.9500\n",
      "Epoch 339/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1141 - accuracy: 0.9576 - val_loss: 0.1265 - val_accuracy: 0.9600\n",
      "Epoch 340/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1149 - accuracy: 0.9554 - val_loss: 0.1265 - val_accuracy: 0.9500\n",
      "Epoch 341/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1301 - accuracy: 0.9505 - val_loss: 0.1253 - val_accuracy: 0.9600\n",
      "Epoch 342/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1204 - accuracy: 0.9525 - val_loss: 0.1512 - val_accuracy: 0.9200\n",
      "Epoch 343/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1529 - accuracy: 0.9338 - val_loss: 0.1253 - val_accuracy: 0.9800\n",
      "Epoch 344/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1370 - accuracy: 0.9503 - val_loss: 0.1584 - val_accuracy: 0.9500\n",
      "Epoch 345/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1425 - accuracy: 0.9540 - val_loss: 0.1315 - val_accuracy: 0.9500\n",
      "Epoch 346/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1253 - accuracy: 0.9580 - val_loss: 0.1239 - val_accuracy: 0.9500\n",
      "Epoch 347/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1206 - accuracy: 0.9585 - val_loss: 0.1223 - val_accuracy: 0.9500\n",
      "Epoch 348/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1198 - accuracy: 0.9616 - val_loss: 0.1202 - val_accuracy: 0.9600\n",
      "Epoch 349/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1092 - accuracy: 0.9588 - val_loss: 0.1203 - val_accuracy: 0.9500\n",
      "Epoch 350/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1190 - accuracy: 0.9541 - val_loss: 0.1199 - val_accuracy: 0.9500\n",
      "Epoch 351/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1041 - accuracy: 0.9637 - val_loss: 0.1168 - val_accuracy: 0.9700\n",
      "Epoch 352/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1103 - accuracy: 0.9595 - val_loss: 0.1211 - val_accuracy: 0.9500\n",
      "Epoch 353/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1123 - accuracy: 0.9577 - val_loss: 0.1176 - val_accuracy: 0.9500\n",
      "Epoch 354/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1103 - accuracy: 0.9562 - val_loss: 0.1161 - val_accuracy: 0.9600\n",
      "Epoch 355/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1083 - accuracy: 0.9603 - val_loss: 0.1137 - val_accuracy: 0.9800\n",
      "Epoch 356/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1175 - accuracy: 0.9570 - val_loss: 0.1133 - val_accuracy: 0.9600\n",
      "Epoch 357/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1090 - accuracy: 0.9590 - val_loss: 0.1176 - val_accuracy: 0.9500\n",
      "Epoch 358/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1071 - accuracy: 0.9590 - val_loss: 0.1154 - val_accuracy: 0.9600\n",
      "Epoch 359/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1060 - accuracy: 0.9615 - val_loss: 0.1147 - val_accuracy: 0.9600\n",
      "Epoch 360/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1163 - accuracy: 0.9580 - val_loss: 0.1142 - val_accuracy: 0.9500\n",
      "Epoch 361/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1136 - accuracy: 0.9582 - val_loss: 0.1104 - val_accuracy: 0.9700\n",
      "Epoch 362/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1093 - accuracy: 0.9656 - val_loss: 0.1125 - val_accuracy: 0.9600\n",
      "Epoch 363/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1266 - accuracy: 0.9570 - val_loss: 0.1108 - val_accuracy: 0.9600\n",
      "Epoch 364/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1173 - accuracy: 0.9522 - val_loss: 0.1102 - val_accuracy: 0.9600\n",
      "Epoch 365/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0997 - accuracy: 0.9633 - val_loss: 0.1122 - val_accuracy: 0.9600\n",
      "Epoch 366/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1119 - accuracy: 0.9527 - val_loss: 0.1102 - val_accuracy: 0.9600\n",
      "Epoch 367/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1180 - accuracy: 0.9522 - val_loss: 0.1076 - val_accuracy: 0.9600\n",
      "Epoch 368/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1040 - accuracy: 0.9580 - val_loss: 0.1218 - val_accuracy: 0.9500\n",
      "Epoch 369/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1189 - accuracy: 0.9554 - val_loss: 0.1119 - val_accuracy: 0.9500\n",
      "Epoch 370/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0999 - accuracy: 0.9652 - val_loss: 0.1097 - val_accuracy: 0.9500\n",
      "Epoch 371/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1074 - accuracy: 0.9593 - val_loss: 0.1079 - val_accuracy: 0.9500\n",
      "Epoch 372/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1197 - accuracy: 0.9510 - val_loss: 0.1057 - val_accuracy: 0.9600\n",
      "Epoch 373/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1117 - accuracy: 0.9538 - val_loss: 0.1047 - val_accuracy: 0.9600\n",
      "Epoch 374/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1003 - accuracy: 0.9636 - val_loss: 0.1071 - val_accuracy: 0.9500\n",
      "Epoch 375/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1080 - accuracy: 0.9572 - val_loss: 0.1041 - val_accuracy: 0.9700\n",
      "Epoch 376/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0949 - accuracy: 0.9655 - val_loss: 0.1012 - val_accuracy: 0.9900\n",
      "Epoch 377/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1289 - accuracy: 0.9525 - val_loss: 0.1010 - val_accuracy: 0.9800\n",
      "Epoch 378/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0974 - accuracy: 0.9612 - val_loss: 0.1286 - val_accuracy: 0.9500\n",
      "Epoch 379/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1211 - accuracy: 0.9549 - val_loss: 0.1151 - val_accuracy: 0.9500\n",
      "Epoch 380/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1125 - accuracy: 0.9607 - val_loss: 0.1083 - val_accuracy: 0.9500\n",
      "Epoch 381/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1035 - accuracy: 0.9680 - val_loss: 0.1034 - val_accuracy: 0.9500\n",
      "Epoch 382/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1023 - accuracy: 0.9596 - val_loss: 0.1033 - val_accuracy: 0.9800\n",
      "Epoch 383/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1134 - accuracy: 0.9594 - val_loss: 0.1007 - val_accuracy: 0.9800\n",
      "Epoch 384/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1051 - accuracy: 0.9624 - val_loss: 0.0985 - val_accuracy: 0.9900\n",
      "Epoch 385/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1221 - accuracy: 0.9515 - val_loss: 0.1331 - val_accuracy: 0.9500\n",
      "Epoch 386/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1094 - accuracy: 0.9638 - val_loss: 0.1058 - val_accuracy: 0.9500\n",
      "Epoch 387/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1097 - accuracy: 0.9506 - val_loss: 0.1182 - val_accuracy: 0.9500\n",
      "Epoch 388/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1052 - accuracy: 0.9645 - val_loss: 0.1019 - val_accuracy: 0.9500\n",
      "Epoch 389/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1091 - accuracy: 0.9617 - val_loss: 0.1037 - val_accuracy: 0.9500\n",
      "Epoch 390/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0971 - accuracy: 0.9682 - val_loss: 0.1017 - val_accuracy: 0.9500\n",
      "Epoch 391/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1067 - accuracy: 0.9615 - val_loss: 0.0985 - val_accuracy: 0.9600\n",
      "Epoch 392/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0995 - accuracy: 0.9603 - val_loss: 0.0971 - val_accuracy: 0.9800\n",
      "Epoch 393/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1012 - accuracy: 0.9680 - val_loss: 0.0976 - val_accuracy: 0.9600\n",
      "Epoch 394/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0940 - accuracy: 0.9672 - val_loss: 0.0968 - val_accuracy: 0.9700\n",
      "Epoch 395/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0917 - accuracy: 0.9669 - val_loss: 0.0955 - val_accuracy: 0.9800\n",
      "Epoch 396/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0995 - accuracy: 0.9630 - val_loss: 0.0944 - val_accuracy: 0.9800\n",
      "Epoch 397/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0977 - accuracy: 0.9623 - val_loss: 0.0961 - val_accuracy: 0.9600\n",
      "Epoch 398/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1087 - accuracy: 0.9536 - val_loss: 0.0955 - val_accuracy: 0.9600\n",
      "Epoch 399/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0962 - accuracy: 0.9634 - val_loss: 0.0947 - val_accuracy: 0.9700\n",
      "Epoch 400/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1060 - accuracy: 0.9522 - val_loss: 0.0933 - val_accuracy: 0.9800\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1038 - accuracy: 0.9573 - val_loss: 0.0934 - val_accuracy: 0.9800\n",
      "Epoch 402/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0971 - accuracy: 0.9656 - val_loss: 0.0925 - val_accuracy: 0.9800\n",
      "Epoch 403/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0946 - accuracy: 0.9684 - val_loss: 0.0900 - val_accuracy: 0.9800\n",
      "Epoch 404/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1003 - accuracy: 0.9581 - val_loss: 0.0933 - val_accuracy: 0.9800\n",
      "Epoch 405/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0912 - accuracy: 0.9654 - val_loss: 0.0949 - val_accuracy: 0.9500\n",
      "Epoch 406/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1056 - accuracy: 0.9540 - val_loss: 0.0880 - val_accuracy: 0.9900\n",
      "Epoch 407/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0984 - accuracy: 0.9599 - val_loss: 0.0887 - val_accuracy: 0.9800\n",
      "Epoch 408/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1036 - accuracy: 0.9575 - val_loss: 0.0887 - val_accuracy: 0.9800\n",
      "Epoch 409/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0961 - accuracy: 0.9593 - val_loss: 0.1227 - val_accuracy: 0.9500\n",
      "Epoch 410/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0969 - accuracy: 0.9637 - val_loss: 0.1001 - val_accuracy: 0.9500\n",
      "Epoch 411/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1014 - accuracy: 0.9604 - val_loss: 0.0920 - val_accuracy: 0.9800\n",
      "Epoch 412/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0978 - accuracy: 0.9601 - val_loss: 0.0871 - val_accuracy: 0.9800\n",
      "Epoch 413/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0939 - accuracy: 0.9632 - val_loss: 0.0876 - val_accuracy: 0.9800\n",
      "Epoch 414/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1038 - accuracy: 0.9570 - val_loss: 0.0896 - val_accuracy: 0.9800\n",
      "Epoch 415/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0892 - accuracy: 0.9655 - val_loss: 0.1071 - val_accuracy: 0.9500\n",
      "Epoch 416/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1067 - accuracy: 0.9642 - val_loss: 0.0866 - val_accuracy: 0.9800\n",
      "Epoch 417/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0957 - accuracy: 0.9658 - val_loss: 0.0837 - val_accuracy: 0.9900\n",
      "Epoch 418/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0996 - accuracy: 0.9581 - val_loss: 0.0891 - val_accuracy: 0.9700\n",
      "Epoch 419/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0852 - accuracy: 0.9732 - val_loss: 0.0869 - val_accuracy: 0.9800\n",
      "Epoch 420/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0988 - accuracy: 0.9652 - val_loss: 0.0856 - val_accuracy: 0.9800\n",
      "Epoch 421/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1010 - accuracy: 0.9610 - val_loss: 0.0862 - val_accuracy: 0.9800\n",
      "Epoch 422/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0971 - accuracy: 0.9642 - val_loss: 0.0854 - val_accuracy: 0.9800\n",
      "Epoch 423/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0940 - accuracy: 0.9651 - val_loss: 0.0836 - val_accuracy: 0.9900\n",
      "Epoch 424/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0941 - accuracy: 0.9680 - val_loss: 0.0836 - val_accuracy: 0.9800\n",
      "Epoch 425/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0917 - accuracy: 0.9620 - val_loss: 0.0854 - val_accuracy: 0.9800\n",
      "Epoch 426/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0859 - accuracy: 0.9673 - val_loss: 0.0854 - val_accuracy: 0.9800\n",
      "Epoch 427/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1016 - accuracy: 0.9661 - val_loss: 0.0835 - val_accuracy: 0.9800\n",
      "Epoch 428/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0928 - accuracy: 0.9667 - val_loss: 0.0841 - val_accuracy: 0.9800\n",
      "Epoch 429/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0793 - accuracy: 0.9729 - val_loss: 0.0805 - val_accuracy: 0.9900\n",
      "Epoch 430/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0957 - accuracy: 0.9564 - val_loss: 0.0827 - val_accuracy: 0.9800\n",
      "Epoch 431/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0846 - accuracy: 0.9679 - val_loss: 0.1122 - val_accuracy: 0.9500\n",
      "Epoch 432/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0983 - accuracy: 0.9688 - val_loss: 0.0885 - val_accuracy: 0.9700\n",
      "Epoch 433/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0868 - accuracy: 0.9723 - val_loss: 0.0815 - val_accuracy: 0.9900\n",
      "Epoch 434/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0964 - accuracy: 0.9626 - val_loss: 0.0797 - val_accuracy: 0.9900\n",
      "Epoch 435/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0999 - accuracy: 0.9574 - val_loss: 0.0820 - val_accuracy: 0.9900\n",
      "Epoch 436/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0976 - accuracy: 0.9636 - val_loss: 0.0788 - val_accuracy: 0.9900\n",
      "Epoch 437/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0916 - accuracy: 0.9672 - val_loss: 0.0785 - val_accuracy: 0.9900\n",
      "Epoch 438/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0949 - accuracy: 0.9696 - val_loss: 0.0770 - val_accuracy: 0.9900\n",
      "Epoch 439/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1040 - accuracy: 0.9607 - val_loss: 0.0763 - val_accuracy: 0.9900\n",
      "Epoch 440/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0922 - accuracy: 0.9622 - val_loss: 0.0777 - val_accuracy: 0.9900\n",
      "Epoch 441/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0904 - accuracy: 0.9620 - val_loss: 0.0770 - val_accuracy: 0.9900\n",
      "Epoch 442/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0992 - accuracy: 0.9626 - val_loss: 0.0752 - val_accuracy: 0.9900\n",
      "Epoch 443/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0810 - accuracy: 0.9667 - val_loss: 0.0769 - val_accuracy: 0.9800\n",
      "Epoch 444/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0861 - accuracy: 0.9674 - val_loss: 0.0812 - val_accuracy: 0.9800\n",
      "Epoch 445/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0933 - accuracy: 0.9626 - val_loss: 0.0788 - val_accuracy: 0.9800\n",
      "Epoch 446/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0820 - accuracy: 0.9698 - val_loss: 0.0784 - val_accuracy: 0.9800\n",
      "Epoch 447/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0826 - accuracy: 0.9697 - val_loss: 0.0738 - val_accuracy: 0.9900\n",
      "Epoch 448/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0898 - accuracy: 0.9623 - val_loss: 0.0752 - val_accuracy: 0.9900\n",
      "Epoch 449/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0837 - accuracy: 0.9673 - val_loss: 0.0761 - val_accuracy: 0.9800\n",
      "Epoch 450/1000\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0889 - accuracy: 0.9690 - val_loss: 0.0876 - val_accuracy: 0.9700\n",
      "Epoch 451/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0976 - accuracy: 0.9659 - val_loss: 0.1053 - val_accuracy: 0.9500\n",
      "Epoch 452/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0993 - accuracy: 0.9597 - val_loss: 0.0864 - val_accuracy: 0.9700\n",
      "Epoch 453/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0814 - accuracy: 0.9686 - val_loss: 0.0773 - val_accuracy: 0.9900\n",
      "Epoch 454/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0890 - accuracy: 0.9669 - val_loss: 0.0743 - val_accuracy: 0.9900\n",
      "Epoch 455/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0881 - accuracy: 0.9694 - val_loss: 0.0842 - val_accuracy: 0.9700\n",
      "Epoch 456/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0826 - accuracy: 0.9703 - val_loss: 0.0756 - val_accuracy: 0.9800\n",
      "Epoch 457/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0785 - accuracy: 0.9696 - val_loss: 0.0744 - val_accuracy: 0.9800\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0812 - accuracy: 0.9687 - val_loss: 0.0781 - val_accuracy: 0.9700\n",
      "Epoch 459/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0836 - accuracy: 0.9688 - val_loss: 0.0779 - val_accuracy: 0.9800\n",
      "Epoch 460/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0857 - accuracy: 0.9692 - val_loss: 0.0733 - val_accuracy: 0.9800\n",
      "Epoch 461/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0846 - accuracy: 0.9645 - val_loss: 0.0722 - val_accuracy: 0.9900\n",
      "Epoch 462/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1053 - accuracy: 0.9577 - val_loss: 0.0730 - val_accuracy: 0.9900\n",
      "Epoch 463/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0797 - accuracy: 0.9689 - val_loss: 0.0718 - val_accuracy: 0.9900\n",
      "Epoch 464/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0887 - accuracy: 0.9649 - val_loss: 0.0734 - val_accuracy: 0.9800\n",
      "Epoch 465/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0964 - accuracy: 0.9620 - val_loss: 0.0745 - val_accuracy: 0.9800\n",
      "Epoch 466/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.9633 - val_loss: 0.0724 - val_accuracy: 0.9800\n",
      "Epoch 467/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0873 - accuracy: 0.9678 - val_loss: 0.0798 - val_accuracy: 0.9700\n",
      "Epoch 468/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0898 - accuracy: 0.9668 - val_loss: 0.0750 - val_accuracy: 0.9700\n",
      "Epoch 469/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0850 - accuracy: 0.9703 - val_loss: 0.1051 - val_accuracy: 0.9500\n",
      "Epoch 470/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0908 - accuracy: 0.9663 - val_loss: 0.0790 - val_accuracy: 0.9700\n",
      "Epoch 471/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0925 - accuracy: 0.9669 - val_loss: 0.0734 - val_accuracy: 0.9800\n",
      "Epoch 472/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0869 - accuracy: 0.9649 - val_loss: 0.0715 - val_accuracy: 0.9900\n",
      "Epoch 473/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0987 - accuracy: 0.9658 - val_loss: 0.0683 - val_accuracy: 0.9900\n",
      "Epoch 474/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0810 - accuracy: 0.9730 - val_loss: 0.0675 - val_accuracy: 0.9900\n",
      "Epoch 475/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0770 - accuracy: 0.9680 - val_loss: 0.1179 - val_accuracy: 0.9300\n",
      "Epoch 476/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1000 - accuracy: 0.9650 - val_loss: 0.0804 - val_accuracy: 0.9700\n",
      "Epoch 477/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0843 - accuracy: 0.9750 - val_loss: 0.0956 - val_accuracy: 0.9600\n",
      "Epoch 478/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0794 - accuracy: 0.9730 - val_loss: 0.0660 - val_accuracy: 0.9900\n",
      "Epoch 479/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0864 - accuracy: 0.9668 - val_loss: 0.0671 - val_accuracy: 0.9900\n",
      "Epoch 480/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0824 - accuracy: 0.9651 - val_loss: 0.0675 - val_accuracy: 0.9900\n",
      "Epoch 481/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0873 - accuracy: 0.9641 - val_loss: 0.0656 - val_accuracy: 0.9900\n",
      "Epoch 482/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0899 - accuracy: 0.9655 - val_loss: 0.0659 - val_accuracy: 0.9900\n",
      "Epoch 483/1000\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.0866 - accuracy: 0.9679 - val_loss: 0.0686 - val_accuracy: 0.9900\n",
      "Epoch 484/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0828 - accuracy: 0.9714 - val_loss: 0.0715 - val_accuracy: 0.9800\n",
      "Epoch 485/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0871 - accuracy: 0.9687 - val_loss: 0.0750 - val_accuracy: 0.9700\n",
      "Epoch 486/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0925 - accuracy: 0.9650 - val_loss: 0.0872 - val_accuracy: 0.9700\n",
      "Epoch 487/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0955 - accuracy: 0.9705 - val_loss: 0.0739 - val_accuracy: 0.9700\n",
      "Epoch 488/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0715 - accuracy: 0.9768 - val_loss: 0.0880 - val_accuracy: 0.9700\n",
      "Epoch 489/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0777 - accuracy: 0.9724 - val_loss: 0.0729 - val_accuracy: 0.9800\n",
      "Epoch 490/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0920 - accuracy: 0.9704 - val_loss: 0.0781 - val_accuracy: 0.9700\n",
      "Epoch 491/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0796 - accuracy: 0.9711 - val_loss: 0.0713 - val_accuracy: 0.9900\n",
      "Epoch 492/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0792 - accuracy: 0.9687 - val_loss: 0.0698 - val_accuracy: 0.9900\n",
      "Epoch 493/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0791 - accuracy: 0.9711 - val_loss: 0.0687 - val_accuracy: 0.9900\n",
      "Epoch 494/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0849 - accuracy: 0.9675 - val_loss: 0.0679 - val_accuracy: 0.9900\n",
      "Epoch 495/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0835 - accuracy: 0.9734 - val_loss: 0.0663 - val_accuracy: 0.9900\n",
      "Epoch 496/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0882 - accuracy: 0.9657 - val_loss: 0.0668 - val_accuracy: 0.9900\n",
      "Epoch 497/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0842 - accuracy: 0.9676 - val_loss: 0.0669 - val_accuracy: 0.9900\n",
      "Epoch 498/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0869 - accuracy: 0.9631 - val_loss: 0.0805 - val_accuracy: 0.9700\n",
      "Epoch 499/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0819 - accuracy: 0.9727 - val_loss: 0.0727 - val_accuracy: 0.9700\n",
      "Epoch 500/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0789 - accuracy: 0.9701 - val_loss: 0.0688 - val_accuracy: 0.9800\n",
      "Epoch 501/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0795 - accuracy: 0.9679 - val_loss: 0.0774 - val_accuracy: 0.9700\n",
      "Epoch 502/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0781 - accuracy: 0.9728 - val_loss: 0.0690 - val_accuracy: 0.9900\n",
      "Epoch 503/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0858 - accuracy: 0.9719 - val_loss: 0.0631 - val_accuracy: 0.9900\n",
      "Epoch 504/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0932 - accuracy: 0.9671 - val_loss: 0.0645 - val_accuracy: 0.9900\n",
      "Epoch 505/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0736 - accuracy: 0.9774 - val_loss: 0.0642 - val_accuracy: 0.9900\n",
      "Epoch 506/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0887 - accuracy: 0.9647 - val_loss: 0.0649 - val_accuracy: 0.9900\n",
      "Epoch 507/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0772 - accuracy: 0.9747 - val_loss: 0.0933 - val_accuracy: 0.9500\n",
      "Epoch 508/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0965 - accuracy: 0.9643 - val_loss: 0.0771 - val_accuracy: 0.9700\n",
      "Epoch 509/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0852 - accuracy: 0.9660 - val_loss: 0.0695 - val_accuracy: 0.9800\n",
      "Epoch 510/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0766 - accuracy: 0.9693 - val_loss: 0.0616 - val_accuracy: 0.9900\n",
      "Epoch 511/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0870 - accuracy: 0.9589 - val_loss: 0.0780 - val_accuracy: 0.9700\n",
      "Epoch 512/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0839 - accuracy: 0.9687 - val_loss: 0.0686 - val_accuracy: 0.9700\n",
      "Epoch 513/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0837 - accuracy: 0.9648 - val_loss: 0.0662 - val_accuracy: 0.9800\n",
      "Epoch 514/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0873 - accuracy: 0.9648 - val_loss: 0.0657 - val_accuracy: 0.9900\n",
      "Epoch 515/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0771 - accuracy: 0.9754 - val_loss: 0.0606 - val_accuracy: 1.0000\n",
      "Epoch 516/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0836 - accuracy: 0.9590 - val_loss: 0.0621 - val_accuracy: 0.9900\n",
      "Epoch 517/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0779 - accuracy: 0.9658 - val_loss: 0.0692 - val_accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0791 - accuracy: 0.9675 - val_loss: 0.0682 - val_accuracy: 0.9800\n",
      "Epoch 519/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0995 - accuracy: 0.9643 - val_loss: 0.0665 - val_accuracy: 0.9800\n",
      "Epoch 520/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0888 - accuracy: 0.9686 - val_loss: 0.0637 - val_accuracy: 0.9800\n",
      "Epoch 521/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0846 - accuracy: 0.9676 - val_loss: 0.0785 - val_accuracy: 0.9600\n",
      "Epoch 522/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0913 - accuracy: 0.9652 - val_loss: 0.0674 - val_accuracy: 0.9800\n",
      "Epoch 523/1000\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0795 - accuracy: 0.9703 - val_loss: 0.0711 - val_accuracy: 0.9600\n",
      "Epoch 524/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0872 - accuracy: 0.9663 - val_loss: 0.0592 - val_accuracy: 0.9900\n",
      "Epoch 525/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0912 - accuracy: 0.9606 - val_loss: 0.0647 - val_accuracy: 0.9700\n",
      "Epoch 526/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0756 - accuracy: 0.9738 - val_loss: 0.0654 - val_accuracy: 0.9800\n",
      "Epoch 527/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0897 - accuracy: 0.9630 - val_loss: 0.0598 - val_accuracy: 0.9900\n",
      "Epoch 528/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0870 - accuracy: 0.9615 - val_loss: 0.0647 - val_accuracy: 0.9800\n",
      "Epoch 529/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0768 - accuracy: 0.9677 - val_loss: 0.0601 - val_accuracy: 1.0000\n",
      "Epoch 530/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0805 - accuracy: 0.9653 - val_loss: 0.0611 - val_accuracy: 0.9800\n",
      "Epoch 531/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1064 - accuracy: 0.9565 - val_loss: 0.0653 - val_accuracy: 0.9700\n",
      "Epoch 532/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0814 - accuracy: 0.9695 - val_loss: 0.0863 - val_accuracy: 0.9600\n",
      "Epoch 533/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0873 - accuracy: 0.9654 - val_loss: 0.0701 - val_accuracy: 0.9700\n",
      "Epoch 534/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9715 - val_loss: 0.0951 - val_accuracy: 0.9600\n",
      "Epoch 535/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0940 - accuracy: 0.9683 - val_loss: 0.0790 - val_accuracy: 0.9600\n",
      "Epoch 536/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0791 - accuracy: 0.9714 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0759 - accuracy: 0.9704 - val_loss: 0.0615 - val_accuracy: 0.9900\n",
      "Epoch 538/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0880 - accuracy: 0.9626 - val_loss: 0.0644 - val_accuracy: 0.9700\n",
      "Epoch 539/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0797 - accuracy: 0.9688 - val_loss: 0.0990 - val_accuracy: 0.9500\n",
      "Epoch 540/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0999 - accuracy: 0.9665 - val_loss: 0.0668 - val_accuracy: 0.9800\n",
      "Epoch 541/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0830 - accuracy: 0.9683 - val_loss: 0.0642 - val_accuracy: 0.9800\n",
      "Epoch 542/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0834 - accuracy: 0.9723 - val_loss: 0.0627 - val_accuracy: 0.9800\n",
      "Epoch 543/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0750 - accuracy: 0.9727 - val_loss: 0.0603 - val_accuracy: 0.9800\n",
      "Epoch 544/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0792 - accuracy: 0.9674 - val_loss: 0.0565 - val_accuracy: 0.9900\n",
      "Epoch 545/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0857 - accuracy: 0.9643 - val_loss: 0.0604 - val_accuracy: 0.9900\n",
      "Epoch 546/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0762 - accuracy: 0.9719 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0862 - accuracy: 0.9617 - val_loss: 0.0581 - val_accuracy: 0.9900\n",
      "Epoch 548/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0865 - accuracy: 0.9662 - val_loss: 0.0613 - val_accuracy: 0.9900\n",
      "Epoch 549/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0693 - accuracy: 0.9720 - val_loss: 0.0625 - val_accuracy: 0.9800\n",
      "Epoch 550/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0783 - accuracy: 0.9714 - val_loss: 0.0568 - val_accuracy: 0.9900\n",
      "Epoch 551/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0740 - accuracy: 0.9703 - val_loss: 0.0720 - val_accuracy: 0.9700\n",
      "Epoch 552/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0909 - accuracy: 0.9707 - val_loss: 0.0639 - val_accuracy: 0.9700\n",
      "Epoch 553/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0830 - accuracy: 0.9730 - val_loss: 0.0553 - val_accuracy: 0.9900\n",
      "Epoch 554/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0754 - accuracy: 0.9693 - val_loss: 0.0577 - val_accuracy: 0.9900\n",
      "Epoch 555/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0734 - accuracy: 0.9744 - val_loss: 0.0594 - val_accuracy: 0.9900\n",
      "Epoch 556/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0879 - accuracy: 0.9652 - val_loss: 0.0588 - val_accuracy: 0.9900\n",
      "Epoch 557/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0673 - accuracy: 0.9748 - val_loss: 0.0616 - val_accuracy: 0.9800\n",
      "Epoch 558/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0887 - accuracy: 0.9583 - val_loss: 0.0597 - val_accuracy: 0.9900\n",
      "Epoch 559/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0755 - accuracy: 0.9685 - val_loss: 0.0606 - val_accuracy: 0.9800\n",
      "Epoch 560/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0784 - accuracy: 0.9686 - val_loss: 0.0722 - val_accuracy: 0.9700\n",
      "Epoch 561/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0729 - accuracy: 0.9724 - val_loss: 0.0617 - val_accuracy: 0.9700\n",
      "Epoch 562/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0710 - accuracy: 0.9737 - val_loss: 0.0609 - val_accuracy: 0.9700\n",
      "Epoch 563/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0720 - accuracy: 0.9754 - val_loss: 0.0586 - val_accuracy: 0.9900\n",
      "Epoch 564/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0813 - accuracy: 0.9669 - val_loss: 0.0590 - val_accuracy: 0.9800\n",
      "Epoch 565/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0849 - accuracy: 0.9629 - val_loss: 0.0587 - val_accuracy: 0.9900\n",
      "Epoch 566/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0764 - accuracy: 0.9718 - val_loss: 0.0572 - val_accuracy: 0.9900\n",
      "Epoch 567/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0914 - accuracy: 0.9613 - val_loss: 0.0587 - val_accuracy: 0.9900\n",
      "Epoch 568/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0741 - accuracy: 0.9725 - val_loss: 0.0533 - val_accuracy: 0.9900\n",
      "Epoch 569/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0805 - accuracy: 0.9604 - val_loss: 0.0560 - val_accuracy: 0.9900\n",
      "Epoch 570/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0769 - accuracy: 0.9715 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 571/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0792 - accuracy: 0.9633 - val_loss: 0.0673 - val_accuracy: 0.9800\n",
      "Epoch 572/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0812 - accuracy: 0.9718 - val_loss: 0.0606 - val_accuracy: 0.9900\n",
      "Epoch 573/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0847 - accuracy: 0.9644 - val_loss: 0.0580 - val_accuracy: 0.9900\n",
      "Epoch 574/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0779 - accuracy: 0.9711 - val_loss: 0.0592 - val_accuracy: 0.9900\n",
      "Epoch 575/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0813 - accuracy: 0.9685 - val_loss: 0.0595 - val_accuracy: 0.9900\n",
      "Epoch 576/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0675 - accuracy: 0.9727 - val_loss: 0.0570 - val_accuracy: 0.9900\n",
      "Epoch 577/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0844 - accuracy: 0.9644 - val_loss: 0.0544 - val_accuracy: 0.9900\n",
      "Epoch 578/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0758 - accuracy: 0.9694 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0768 - accuracy: 0.9666 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
      "Epoch 580/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0774 - accuracy: 0.9672 - val_loss: 0.0552 - val_accuracy: 0.9900\n",
      "Epoch 581/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0722 - accuracy: 0.9746 - val_loss: 0.0553 - val_accuracy: 0.9900\n",
      "Epoch 582/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0630 - accuracy: 0.9743 - val_loss: 0.0571 - val_accuracy: 0.9900\n",
      "Epoch 583/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0752 - accuracy: 0.9652 - val_loss: 0.0570 - val_accuracy: 0.9900\n",
      "Epoch 584/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0835 - accuracy: 0.9662 - val_loss: 0.0572 - val_accuracy: 0.9900\n",
      "Epoch 585/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0870 - accuracy: 0.9643 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 586/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0894 - accuracy: 0.9655 - val_loss: 0.0520 - val_accuracy: 1.0000\n",
      "Epoch 587/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0774 - accuracy: 0.9639 - val_loss: 0.0821 - val_accuracy: 0.9700\n",
      "Epoch 588/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0756 - accuracy: 0.9759 - val_loss: 0.0620 - val_accuracy: 0.9800\n",
      "Epoch 589/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0697 - accuracy: 0.9750 - val_loss: 0.0590 - val_accuracy: 0.9800\n",
      "Epoch 590/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0722 - accuracy: 0.9735 - val_loss: 0.0577 - val_accuracy: 0.9800\n",
      "Epoch 591/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0817 - accuracy: 0.9655 - val_loss: 0.0563 - val_accuracy: 0.9900\n",
      "Epoch 592/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0806 - accuracy: 0.9706 - val_loss: 0.0559 - val_accuracy: 0.9900\n",
      "Epoch 593/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0769 - accuracy: 0.9736 - val_loss: 0.0512 - val_accuracy: 0.9900\n",
      "Epoch 594/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0739 - accuracy: 0.9681 - val_loss: 0.0534 - val_accuracy: 0.9900\n",
      "Epoch 595/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0799 - accuracy: 0.9686 - val_loss: 0.0554 - val_accuracy: 0.9900\n",
      "Epoch 596/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0824 - accuracy: 0.9676 - val_loss: 0.0562 - val_accuracy: 0.9900\n",
      "Epoch 597/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0829 - accuracy: 0.9675 - val_loss: 0.0542 - val_accuracy: 0.9900\n",
      "Epoch 598/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0779 - accuracy: 0.9716 - val_loss: 0.0543 - val_accuracy: 0.9900\n",
      "Epoch 599/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0776 - accuracy: 0.9692 - val_loss: 0.0552 - val_accuracy: 0.9900\n",
      "Epoch 600/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0817 - accuracy: 0.9672 - val_loss: 0.0601 - val_accuracy: 1.0000\n",
      "Epoch 601/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0940 - accuracy: 0.9595 - val_loss: 0.0527 - val_accuracy: 0.9900\n",
      "Epoch 602/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0795 - accuracy: 0.9682 - val_loss: 0.0554 - val_accuracy: 0.9800\n",
      "Epoch 603/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0817 - accuracy: 0.9672 - val_loss: 0.0564 - val_accuracy: 0.9800\n",
      "Epoch 604/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0711 - accuracy: 0.9738 - val_loss: 0.0517 - val_accuracy: 0.9900\n",
      "Epoch 605/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0744 - accuracy: 0.9660 - val_loss: 0.0533 - val_accuracy: 0.9900\n",
      "Epoch 606/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0677 - accuracy: 0.9741 - val_loss: 0.0566 - val_accuracy: 0.9800\n",
      "Epoch 607/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0953 - accuracy: 0.9640 - val_loss: 0.0556 - val_accuracy: 0.9800\n",
      "Epoch 608/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0796 - accuracy: 0.9682 - val_loss: 0.0572 - val_accuracy: 0.9800\n",
      "Epoch 609/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9742 - val_loss: 0.0563 - val_accuracy: 0.9800\n",
      "Epoch 610/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0787 - accuracy: 0.9703 - val_loss: 0.0593 - val_accuracy: 0.9700\n",
      "Epoch 611/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0759 - accuracy: 0.9746 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
      "Epoch 612/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0858 - accuracy: 0.9629 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
      "Epoch 613/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0780 - accuracy: 0.9710 - val_loss: 0.0533 - val_accuracy: 1.0000\n",
      "Epoch 614/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0732 - accuracy: 0.9712 - val_loss: 0.0591 - val_accuracy: 0.9800\n",
      "Epoch 615/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0716 - accuracy: 0.9760 - val_loss: 0.0498 - val_accuracy: 1.0000\n",
      "Epoch 616/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0800 - accuracy: 0.9660 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
      "Epoch 617/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0654 - accuracy: 0.9713 - val_loss: 0.0534 - val_accuracy: 1.0000\n",
      "Epoch 618/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0738 - accuracy: 0.9694 - val_loss: 0.0536 - val_accuracy: 1.0000\n",
      "Epoch 619/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0682 - accuracy: 0.9694 - val_loss: 0.0555 - val_accuracy: 0.9800\n",
      "Epoch 620/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1008 - accuracy: 0.9609 - val_loss: 0.0555 - val_accuracy: 0.9800\n",
      "Epoch 621/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0738 - accuracy: 0.9706 - val_loss: 0.0541 - val_accuracy: 0.9800\n",
      "Epoch 622/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0728 - accuracy: 0.9711 - val_loss: 0.0643 - val_accuracy: 0.9700\n",
      "Epoch 623/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0720 - accuracy: 0.9765 - val_loss: 0.0634 - val_accuracy: 0.9700\n",
      "Epoch 624/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0997 - accuracy: 0.9612 - val_loss: 0.0564 - val_accuracy: 0.9700\n",
      "Epoch 625/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0641 - accuracy: 0.9769 - val_loss: 0.0520 - val_accuracy: 1.0000\n",
      "Epoch 626/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0673 - accuracy: 0.9779 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 627/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0720 - accuracy: 0.9707 - val_loss: 0.0525 - val_accuracy: 0.9900\n",
      "Epoch 628/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0670 - accuracy: 0.9713 - val_loss: 0.0535 - val_accuracy: 0.9900\n",
      "Epoch 629/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0640 - accuracy: 0.9786 - val_loss: 0.0531 - val_accuracy: 0.9900\n",
      "Epoch 630/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9692 - val_loss: 0.0538 - val_accuracy: 0.9900\n",
      "Epoch 631/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0710 - accuracy: 0.9708 - val_loss: 0.0527 - val_accuracy: 0.9900\n",
      "Epoch 632/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0677 - accuracy: 0.9769 - val_loss: 0.0528 - val_accuracy: 0.9900\n",
      "Epoch 633/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0720 - accuracy: 0.9766 - val_loss: 0.0527 - val_accuracy: 0.9900\n",
      "Epoch 634/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0800 - accuracy: 0.9693 - val_loss: 0.0521 - val_accuracy: 0.9900\n",
      "Epoch 635/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0759 - accuracy: 0.9699 - val_loss: 0.0476 - val_accuracy: 0.9900\n",
      "Epoch 636/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0685 - accuracy: 0.9763 - val_loss: 0.0506 - val_accuracy: 0.9900\n",
      "Epoch 637/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0735 - accuracy: 0.9699 - val_loss: 0.0520 - val_accuracy: 0.9900\n",
      "Epoch 638/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0745 - accuracy: 0.9690 - val_loss: 0.0681 - val_accuracy: 0.9700\n",
      "Epoch 639/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0849 - accuracy: 0.9687 - val_loss: 0.0618 - val_accuracy: 0.9700\n",
      "Epoch 640/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0801 - accuracy: 0.9733 - val_loss: 0.0560 - val_accuracy: 0.9700\n",
      "Epoch 641/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0783 - accuracy: 0.9672 - val_loss: 0.0488 - val_accuracy: 0.9900\n",
      "Epoch 642/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0866 - accuracy: 0.9602 - val_loss: 0.0513 - val_accuracy: 0.9900\n",
      "Epoch 643/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0669 - accuracy: 0.9739 - val_loss: 0.0589 - val_accuracy: 0.9800\n",
      "Epoch 644/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1079 - accuracy: 0.9518 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 645/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0885 - accuracy: 0.9598 - val_loss: 0.0523 - val_accuracy: 0.9800\n",
      "Epoch 646/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0754 - accuracy: 0.9708 - val_loss: 0.0537 - val_accuracy: 0.9800\n",
      "Epoch 647/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0784 - accuracy: 0.9717 - val_loss: 0.0560 - val_accuracy: 0.9700\n",
      "Epoch 648/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0714 - accuracy: 0.9737 - val_loss: 0.0529 - val_accuracy: 0.9900\n",
      "Epoch 649/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0746 - accuracy: 0.9682 - val_loss: 0.0531 - val_accuracy: 0.9900\n",
      "Epoch 650/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0760 - accuracy: 0.9686 - val_loss: 0.0525 - val_accuracy: 0.9900\n",
      "Epoch 651/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0710 - accuracy: 0.9740 - val_loss: 0.0535 - val_accuracy: 0.9800\n",
      "Epoch 652/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0599 - accuracy: 0.9782 - val_loss: 0.0534 - val_accuracy: 0.9800\n",
      "Epoch 653/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0838 - accuracy: 0.9657 - val_loss: 0.0529 - val_accuracy: 0.9900\n",
      "Epoch 654/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0863 - accuracy: 0.9635 - val_loss: 0.0821 - val_accuracy: 0.9600\n",
      "Epoch 655/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0888 - accuracy: 0.9617 - val_loss: 0.0616 - val_accuracy: 0.9700\n",
      "Epoch 656/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0860 - accuracy: 0.9697 - val_loss: 0.0559 - val_accuracy: 0.9800\n",
      "Epoch 657/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0689 - accuracy: 0.9768 - val_loss: 0.0532 - val_accuracy: 0.9800\n",
      "Epoch 658/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0700 - accuracy: 0.9688 - val_loss: 0.0532 - val_accuracy: 0.9800\n",
      "Epoch 659/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0795 - accuracy: 0.9656 - val_loss: 0.0573 - val_accuracy: 0.9700\n",
      "Epoch 660/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0758 - accuracy: 0.9740 - val_loss: 0.0563 - val_accuracy: 0.9700\n",
      "Epoch 661/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0723 - accuracy: 0.9749 - val_loss: 0.0518 - val_accuracy: 0.9900\n",
      "Epoch 662/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0733 - accuracy: 0.9714 - val_loss: 0.0523 - val_accuracy: 0.9900\n",
      "Epoch 663/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0756 - accuracy: 0.9693 - val_loss: 0.0777 - val_accuracy: 0.9600\n",
      "Epoch 664/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0873 - accuracy: 0.9677 - val_loss: 0.0577 - val_accuracy: 0.9800\n",
      "Epoch 665/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0636 - accuracy: 0.9747 - val_loss: 0.0548 - val_accuracy: 0.9800\n",
      "Epoch 666/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0772 - accuracy: 0.9662 - val_loss: 0.0485 - val_accuracy: 0.9900\n",
      "Epoch 667/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0795 - accuracy: 0.9633 - val_loss: 0.0560 - val_accuracy: 0.9900\n",
      "Epoch 668/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0732 - accuracy: 0.9739 - val_loss: 0.0548 - val_accuracy: 0.9900\n",
      "Epoch 669/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0622 - accuracy: 0.9790 - val_loss: 0.0524 - val_accuracy: 0.9900\n",
      "Epoch 670/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0780 - accuracy: 0.9670 - val_loss: 0.0525 - val_accuracy: 0.9900\n",
      "Epoch 671/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0687 - accuracy: 0.9735 - val_loss: 0.0621 - val_accuracy: 0.9700\n",
      "Epoch 672/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0696 - accuracy: 0.9767 - val_loss: 0.0561 - val_accuracy: 0.9900\n",
      "Epoch 673/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0986 - accuracy: 0.9535 - val_loss: 0.0491 - val_accuracy: 0.9900\n",
      "Epoch 674/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0709 - accuracy: 0.9662 - val_loss: 0.0524 - val_accuracy: 0.9900\n",
      "Epoch 675/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0822 - accuracy: 0.9671 - val_loss: 0.0515 - val_accuracy: 0.9900\n",
      "Epoch 676/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0725 - accuracy: 0.9696 - val_loss: 0.0587 - val_accuracy: 0.9700\n",
      "Epoch 677/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0718 - accuracy: 0.9758 - val_loss: 0.0887 - val_accuracy: 0.9500\n",
      "Epoch 678/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0838 - accuracy: 0.9745 - val_loss: 0.0603 - val_accuracy: 0.9800\n",
      "Epoch 679/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0688 - accuracy: 0.9764 - val_loss: 0.0538 - val_accuracy: 0.9900\n",
      "Epoch 680/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0884 - accuracy: 0.9673 - val_loss: 0.0523 - val_accuracy: 0.9900\n",
      "Epoch 681/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0807 - accuracy: 0.9726 - val_loss: 0.0470 - val_accuracy: 0.9900\n",
      "Epoch 682/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0709 - accuracy: 0.9739 - val_loss: 0.0712 - val_accuracy: 0.9600\n",
      "Epoch 683/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0816 - accuracy: 0.9730 - val_loss: 0.0586 - val_accuracy: 0.9800\n",
      "Epoch 684/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0723 - accuracy: 0.9769 - val_loss: 0.0530 - val_accuracy: 0.9900\n",
      "Epoch 685/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0831 - accuracy: 0.9633 - val_loss: 0.0491 - val_accuracy: 0.9900\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0838 - accuracy: 0.9585 - val_loss: 0.0723 - val_accuracy: 0.9700\n",
      "Epoch 687/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0747 - accuracy: 0.9735 - val_loss: 0.0538 - val_accuracy: 0.9800\n",
      "Epoch 688/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0815 - accuracy: 0.9636 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
      "Epoch 689/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0698 - accuracy: 0.9711 - val_loss: 0.0504 - val_accuracy: 0.9900\n",
      "Epoch 690/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0812 - accuracy: 0.9674 - val_loss: 0.0502 - val_accuracy: 0.9900\n",
      "Epoch 691/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0704 - accuracy: 0.9709 - val_loss: 0.0504 - val_accuracy: 0.9900\n",
      "Epoch 692/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0812 - accuracy: 0.9654 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
      "Epoch 693/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0832 - accuracy: 0.9664 - val_loss: 0.0519 - val_accuracy: 0.9800\n",
      "Epoch 694/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0847 - accuracy: 0.9641 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
      "Epoch 695/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0771 - accuracy: 0.9741 - val_loss: 0.0650 - val_accuracy: 0.9800\n",
      "Epoch 696/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0725 - accuracy: 0.9708 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 697/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0814 - accuracy: 0.9685 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "Epoch 698/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0735 - accuracy: 0.9693 - val_loss: 0.0630 - val_accuracy: 0.9700\n",
      "Epoch 699/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0758 - accuracy: 0.9765 - val_loss: 0.0540 - val_accuracy: 0.9800\n",
      "Epoch 700/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0714 - accuracy: 0.9741 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 701/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0764 - accuracy: 0.9645 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 702/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0716 - accuracy: 0.9727 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
      "Epoch 703/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0772 - accuracy: 0.9679 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
      "Epoch 704/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0770 - accuracy: 0.9687 - val_loss: 0.0514 - val_accuracy: 0.9800\n",
      "Epoch 705/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0759 - accuracy: 0.9729 - val_loss: 0.0522 - val_accuracy: 0.9900\n",
      "Epoch 706/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0709 - accuracy: 0.9733 - val_loss: 0.0653 - val_accuracy: 0.9700\n",
      "Epoch 707/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0814 - accuracy: 0.9754 - val_loss: 0.0563 - val_accuracy: 0.9800\n",
      "Epoch 708/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0766 - accuracy: 0.9713 - val_loss: 0.0506 - val_accuracy: 0.9900\n",
      "Epoch 709/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0823 - accuracy: 0.9642 - val_loss: 0.0585 - val_accuracy: 0.9700\n",
      "Epoch 710/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0746 - accuracy: 0.9727 - val_loss: 0.0531 - val_accuracy: 0.9800\n",
      "Epoch 711/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0848 - accuracy: 0.9681 - val_loss: 0.0535 - val_accuracy: 0.9700\n",
      "Epoch 712/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0760 - accuracy: 0.9687 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 713/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0796 - accuracy: 0.9715 - val_loss: 0.0855 - val_accuracy: 0.9600\n",
      "Epoch 714/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0773 - accuracy: 0.9722 - val_loss: 0.0626 - val_accuracy: 0.9800\n",
      "Epoch 715/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0886 - accuracy: 0.9642 - val_loss: 0.0486 - val_accuracy: 0.9900\n",
      "Epoch 716/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0726 - accuracy: 0.9704 - val_loss: 0.0516 - val_accuracy: 0.9800\n",
      "Epoch 717/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0855 - accuracy: 0.9630 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
      "Epoch 718/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0784 - accuracy: 0.9708 - val_loss: 0.0556 - val_accuracy: 0.9800\n",
      "Epoch 719/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0676 - accuracy: 0.9737 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
      "Epoch 720/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0839 - accuracy: 0.9556 - val_loss: 0.0603 - val_accuracy: 0.9800\n",
      "Epoch 721/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0768 - accuracy: 0.9715 - val_loss: 0.0716 - val_accuracy: 0.9700\n",
      "Epoch 722/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0789 - accuracy: 0.9659 - val_loss: 0.0603 - val_accuracy: 0.9800\n",
      "Epoch 723/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0832 - accuracy: 0.9658 - val_loss: 0.0515 - val_accuracy: 0.9800\n",
      "Epoch 724/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0722 - accuracy: 0.9709 - val_loss: 0.0522 - val_accuracy: 0.9800\n",
      "Epoch 725/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0740 - accuracy: 0.9691 - val_loss: 0.0487 - val_accuracy: 0.9900\n",
      "Epoch 726/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0682 - accuracy: 0.9758 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 727/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0634 - accuracy: 0.9754 - val_loss: 0.0507 - val_accuracy: 0.9800\n",
      "Epoch 728/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0823 - accuracy: 0.9696 - val_loss: 0.0507 - val_accuracy: 0.9800\n",
      "Epoch 729/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0733 - accuracy: 0.9724 - val_loss: 0.0589 - val_accuracy: 0.9700\n",
      "Epoch 730/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0707 - accuracy: 0.9761 - val_loss: 0.0497 - val_accuracy: 0.9800\n",
      "Epoch 731/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0701 - accuracy: 0.9753 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
      "Epoch 732/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0692 - accuracy: 0.9748 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "Epoch 733/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0763 - accuracy: 0.9698 - val_loss: 0.0489 - val_accuracy: 0.9900\n",
      "Epoch 734/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0775 - accuracy: 0.9695 - val_loss: 0.0489 - val_accuracy: 0.9900\n",
      "Epoch 735/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0772 - accuracy: 0.9697 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 736/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0690 - accuracy: 0.9719 - val_loss: 0.0917 - val_accuracy: 0.9400\n",
      "Epoch 737/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0734 - accuracy: 0.9726 - val_loss: 0.0522 - val_accuracy: 0.9900\n",
      "Epoch 738/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0703 - accuracy: 0.9737 - val_loss: 0.0467 - val_accuracy: 0.9900\n",
      "Epoch 739/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0677 - accuracy: 0.9756 - val_loss: 0.0478 - val_accuracy: 0.9900\n",
      "Epoch 740/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0686 - accuracy: 0.9734 - val_loss: 0.0748 - val_accuracy: 0.9500\n",
      "Epoch 741/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1145 - accuracy: 0.9484 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
      "Epoch 742/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0807 - accuracy: 0.9614 - val_loss: 0.0465 - val_accuracy: 0.9900\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0769 - accuracy: 0.9701 - val_loss: 0.0444 - val_accuracy: 1.0000\n",
      "Epoch 744/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0770 - accuracy: 0.9672 - val_loss: 0.0544 - val_accuracy: 0.9800\n",
      "Epoch 745/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0887 - accuracy: 0.9626 - val_loss: 0.0813 - val_accuracy: 0.9500\n",
      "Epoch 746/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0912 - accuracy: 0.9625 - val_loss: 0.0572 - val_accuracy: 0.9800\n",
      "Epoch 747/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0768 - accuracy: 0.9656 - val_loss: 0.0493 - val_accuracy: 0.9900\n",
      "Epoch 748/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0622 - accuracy: 0.9755 - val_loss: 0.0606 - val_accuracy: 0.9800\n",
      "Epoch 749/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0810 - accuracy: 0.9672 - val_loss: 0.0521 - val_accuracy: 0.9800\n",
      "Epoch 750/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0687 - accuracy: 0.9703 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
      "Epoch 751/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0782 - accuracy: 0.9680 - val_loss: 0.0926 - val_accuracy: 0.9600\n",
      "Epoch 752/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0723 - accuracy: 0.9722 - val_loss: 0.0649 - val_accuracy: 0.9800\n",
      "Epoch 753/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0668 - accuracy: 0.9702 - val_loss: 0.0553 - val_accuracy: 0.9900\n",
      "Epoch 754/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0651 - accuracy: 0.9717 - val_loss: 0.0511 - val_accuracy: 0.9900\n",
      "Epoch 755/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0732 - accuracy: 0.9690 - val_loss: 0.0516 - val_accuracy: 0.9900\n",
      "Epoch 756/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0794 - accuracy: 0.9679 - val_loss: 0.0511 - val_accuracy: 0.9900\n",
      "Epoch 757/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0816 - accuracy: 0.9627 - val_loss: 0.0497 - val_accuracy: 0.9900\n",
      "Epoch 758/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0749 - accuracy: 0.9700 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
      "Epoch 759/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0877 - accuracy: 0.9560 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
      "Epoch 760/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0736 - accuracy: 0.9716 - val_loss: 0.0485 - val_accuracy: 0.9900\n",
      "Epoch 761/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0682 - accuracy: 0.9690 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 762/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0750 - accuracy: 0.9697 - val_loss: 0.1366 - val_accuracy: 0.9300\n",
      "Epoch 763/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1012 - accuracy: 0.9615 - val_loss: 0.0673 - val_accuracy: 0.9700\n",
      "Epoch 764/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0773 - accuracy: 0.9754 - val_loss: 0.0571 - val_accuracy: 0.9700\n",
      "Epoch 765/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0740 - accuracy: 0.9743 - val_loss: 0.0506 - val_accuracy: 0.9900\n",
      "Epoch 766/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0786 - accuracy: 0.9725 - val_loss: 0.0490 - val_accuracy: 0.9900\n",
      "Epoch 767/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0695 - accuracy: 0.9737 - val_loss: 0.0512 - val_accuracy: 0.9900\n",
      "Epoch 768/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0720 - accuracy: 0.9742 - val_loss: 0.0706 - val_accuracy: 0.9700\n",
      "Epoch 769/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0786 - accuracy: 0.9723 - val_loss: 0.0548 - val_accuracy: 0.9800\n",
      "Epoch 770/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0803 - accuracy: 0.9717 - val_loss: 0.0496 - val_accuracy: 0.9900\n",
      "Epoch 771/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0806 - accuracy: 0.9676 - val_loss: 0.0514 - val_accuracy: 0.9900\n",
      "Epoch 772/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0761 - accuracy: 0.9669 - val_loss: 0.0505 - val_accuracy: 0.9800\n",
      "Epoch 773/1000\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0742 - accuracy: 0.9734 - val_loss: 0.0500 - val_accuracy: 0.9900\n",
      "Epoch 774/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0783 - accuracy: 0.9711 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 775/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0744 - accuracy: 0.9720 - val_loss: 0.0514 - val_accuracy: 0.9900\n",
      "Epoch 776/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0915 - accuracy: 0.9581 - val_loss: 0.0485 - val_accuracy: 0.9900\n",
      "Epoch 777/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0703 - accuracy: 0.9707 - val_loss: 0.0484 - val_accuracy: 0.9900\n",
      "Epoch 778/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0721 - accuracy: 0.9692 - val_loss: 0.0509 - val_accuracy: 0.9700\n",
      "Epoch 779/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0777 - accuracy: 0.9670 - val_loss: 0.0500 - val_accuracy: 0.9800\n",
      "Epoch 780/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0832 - accuracy: 0.9661 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 781/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0716 - accuracy: 0.9683 - val_loss: 0.0464 - val_accuracy: 0.9900\n",
      "Epoch 782/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0642 - accuracy: 0.9709 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "Epoch 783/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0728 - accuracy: 0.9687 - val_loss: 0.0472 - val_accuracy: 0.9900\n",
      "Epoch 784/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0726 - accuracy: 0.9732 - val_loss: 0.0473 - val_accuracy: 0.9900\n",
      "Epoch 785/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0762 - accuracy: 0.9715 - val_loss: 0.0476 - val_accuracy: 0.9900\n",
      "Epoch 786/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0727 - accuracy: 0.9648 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 787/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0649 - accuracy: 0.9700 - val_loss: 0.0481 - val_accuracy: 0.9900\n",
      "Epoch 788/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0778 - accuracy: 0.9703 - val_loss: 0.0452 - val_accuracy: 1.0000\n",
      "Epoch 789/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0767 - accuracy: 0.9696 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 790/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0679 - accuracy: 0.9650 - val_loss: 0.0738 - val_accuracy: 0.9700\n",
      "Epoch 791/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0687 - accuracy: 0.9742 - val_loss: 0.0510 - val_accuracy: 0.9900\n",
      "Epoch 792/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0724 - accuracy: 0.9699 - val_loss: 0.0516 - val_accuracy: 0.9800\n",
      "Epoch 793/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0709 - accuracy: 0.9779 - val_loss: 0.0487 - val_accuracy: 0.9900\n",
      "Epoch 794/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0803 - accuracy: 0.9691 - val_loss: 0.0468 - val_accuracy: 0.9900\n",
      "Epoch 795/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0642 - accuracy: 0.9758 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 796/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0803 - accuracy: 0.9641 - val_loss: 0.0435 - val_accuracy: 1.0000\n",
      "Epoch 797/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0746 - accuracy: 0.9674 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 798/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0658 - accuracy: 0.9733 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
      "Epoch 799/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0712 - accuracy: 0.9700 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
      "Epoch 800/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0680 - accuracy: 0.9726 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
      "Epoch 801/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0679 - accuracy: 0.9746 - val_loss: 0.0461 - val_accuracy: 0.9900\n",
      "Epoch 802/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0725 - accuracy: 0.9660 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 803/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0750 - accuracy: 0.9709 - val_loss: 0.0444 - val_accuracy: 1.0000\n",
      "Epoch 804/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0730 - accuracy: 0.9668 - val_loss: 0.0544 - val_accuracy: 0.9800\n",
      "Epoch 805/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0864 - accuracy: 0.9622 - val_loss: 0.0471 - val_accuracy: 0.9900\n",
      "Epoch 806/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0743 - accuracy: 0.9657 - val_loss: 0.0468 - val_accuracy: 0.9900\n",
      "Epoch 807/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0778 - accuracy: 0.9632 - val_loss: 0.0447 - val_accuracy: 0.9900\n",
      "Epoch 808/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0592 - accuracy: 0.9749 - val_loss: 0.0896 - val_accuracy: 0.9600\n",
      "Epoch 809/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0881 - accuracy: 0.9659 - val_loss: 0.1332 - val_accuracy: 0.9300\n",
      "Epoch 810/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0871 - accuracy: 0.9655 - val_loss: 0.0476 - val_accuracy: 0.9900\n",
      "Epoch 811/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0805 - accuracy: 0.9634 - val_loss: 0.0474 - val_accuracy: 0.9900\n",
      "Epoch 812/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0750 - accuracy: 0.9661 - val_loss: 0.0476 - val_accuracy: 0.9900\n",
      "Epoch 813/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0866 - accuracy: 0.9649 - val_loss: 0.0465 - val_accuracy: 0.9900\n",
      "Epoch 814/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0696 - accuracy: 0.9714 - val_loss: 0.0536 - val_accuracy: 0.9800\n",
      "Epoch 815/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0650 - accuracy: 0.9766 - val_loss: 0.0485 - val_accuracy: 0.9900\n",
      "Epoch 816/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0654 - accuracy: 0.9698 - val_loss: 0.0473 - val_accuracy: 0.9900\n",
      "Epoch 817/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0717 - accuracy: 0.9652 - val_loss: 0.0470 - val_accuracy: 0.9900\n",
      "Epoch 818/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0793 - accuracy: 0.9716 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
      "Epoch 819/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0837 - accuracy: 0.9582 - val_loss: 0.0457 - val_accuracy: 0.9900\n",
      "Epoch 820/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0770 - accuracy: 0.9673 - val_loss: 0.0485 - val_accuracy: 0.9800\n",
      "Epoch 821/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0600 - accuracy: 0.9799 - val_loss: 0.0493 - val_accuracy: 0.9800\n",
      "Epoch 822/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0699 - accuracy: 0.9757 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0784 - accuracy: 0.9666 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0751 - accuracy: 0.9694 - val_loss: 0.0549 - val_accuracy: 0.9800\n",
      "Epoch 825/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0707 - accuracy: 0.9762 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0703 - accuracy: 0.9672 - val_loss: 0.0425 - val_accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0780 - accuracy: 0.9695 - val_loss: 0.0520 - val_accuracy: 0.9900\n",
      "Epoch 828/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0743 - accuracy: 0.9760 - val_loss: 0.0448 - val_accuracy: 0.9900\n",
      "Epoch 829/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0794 - accuracy: 0.9684 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
      "Epoch 830/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0747 - accuracy: 0.9696 - val_loss: 0.0479 - val_accuracy: 0.9900\n",
      "Epoch 831/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0636 - accuracy: 0.9779 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0673 - accuracy: 0.9725 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0733 - accuracy: 0.9691 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0637 - accuracy: 0.9751 - val_loss: 0.0575 - val_accuracy: 0.9800\n",
      "Epoch 835/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0827 - accuracy: 0.9706 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 836/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0899 - accuracy: 0.9566 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0707 - accuracy: 0.9682 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0722 - accuracy: 0.9681 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0698 - accuracy: 0.9709 - val_loss: 0.0448 - val_accuracy: 0.9900\n",
      "Epoch 840/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0756 - accuracy: 0.9699 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
      "Epoch 841/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0682 - accuracy: 0.9709 - val_loss: 0.0506 - val_accuracy: 0.9800\n",
      "Epoch 842/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0665 - accuracy: 0.9805 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0710 - accuracy: 0.9670 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0637 - accuracy: 0.9765 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0714 - accuracy: 0.9747 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0705 - accuracy: 0.9658 - val_loss: 0.0576 - val_accuracy: 0.9800\n",
      "Epoch 847/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0735 - accuracy: 0.9750 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0626 - accuracy: 0.9763 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0708 - accuracy: 0.9735 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
      "Epoch 850/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0593 - accuracy: 0.9754 - val_loss: 0.0466 - val_accuracy: 1.0000\n",
      "Epoch 851/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1018 - accuracy: 0.9547 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0733 - accuracy: 0.9683 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0685 - accuracy: 0.9727 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0778 - accuracy: 0.9667 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0602 - accuracy: 0.9742 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0670 - accuracy: 0.9700 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
      "Epoch 857/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0739 - accuracy: 0.9690 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0683 - accuracy: 0.9677 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0711 - accuracy: 0.9718 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
      "Epoch 860/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0631 - accuracy: 0.9724 - val_loss: 0.0972 - val_accuracy: 0.9500\n",
      "Epoch 861/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0809 - accuracy: 0.9674 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "Epoch 862/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0797 - accuracy: 0.9600 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0704 - accuracy: 0.9663 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 864/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0693 - accuracy: 0.9716 - val_loss: 0.0534 - val_accuracy: 0.9800\n",
      "Epoch 865/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0786 - accuracy: 0.9679 - val_loss: 0.0522 - val_accuracy: 0.9900\n",
      "Epoch 866/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0770 - accuracy: 0.9706 - val_loss: 0.1208 - val_accuracy: 0.9400\n",
      "Epoch 867/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1085 - accuracy: 0.9595 - val_loss: 0.0467 - val_accuracy: 0.9900\n",
      "Epoch 868/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0780 - accuracy: 0.9653 - val_loss: 0.0472 - val_accuracy: 0.9900\n",
      "Epoch 869/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0703 - accuracy: 0.9738 - val_loss: 0.0442 - val_accuracy: 0.9900\n",
      "Epoch 870/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0668 - accuracy: 0.9754 - val_loss: 0.0453 - val_accuracy: 0.9900\n",
      "Epoch 871/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0597 - accuracy: 0.9740 - val_loss: 0.0812 - val_accuracy: 0.9500\n",
      "Epoch 872/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0874 - accuracy: 0.9708 - val_loss: 0.0501 - val_accuracy: 0.9900\n",
      "Epoch 873/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0779 - accuracy: 0.9692 - val_loss: 0.0440 - val_accuracy: 0.9900\n",
      "Epoch 874/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0729 - accuracy: 0.9696 - val_loss: 0.0472 - val_accuracy: 0.9900\n",
      "Epoch 875/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0726 - accuracy: 0.9670 - val_loss: 0.0645 - val_accuracy: 0.9700\n",
      "Epoch 876/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0718 - accuracy: 0.9764 - val_loss: 0.0493 - val_accuracy: 0.9900\n",
      "Epoch 877/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0720 - accuracy: 0.9731 - val_loss: 0.0464 - val_accuracy: 0.9900\n",
      "Epoch 878/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0878 - accuracy: 0.9635 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0648 - accuracy: 0.9716 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0824 - accuracy: 0.9610 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0739 - accuracy: 0.9655 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0864 - accuracy: 0.9636 - val_loss: 0.0411 - val_accuracy: 0.9900\n",
      "Epoch 883/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0725 - accuracy: 0.9724 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 884/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0710 - accuracy: 0.9694 - val_loss: 0.0425 - val_accuracy: 0.9900\n",
      "Epoch 885/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0865 - accuracy: 0.9642 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "Epoch 886/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0751 - accuracy: 0.9654 - val_loss: 0.0459 - val_accuracy: 0.9900\n",
      "Epoch 887/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0796 - accuracy: 0.9709 - val_loss: 0.0431 - val_accuracy: 0.9900\n",
      "Epoch 888/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0656 - accuracy: 0.9722 - val_loss: 0.0422 - val_accuracy: 0.9900\n",
      "Epoch 889/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0613 - accuracy: 0.9768 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0751 - accuracy: 0.9660 - val_loss: 0.0418 - val_accuracy: 0.9900\n",
      "Epoch 891/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0704 - accuracy: 0.9778 - val_loss: 0.0422 - val_accuracy: 0.9900\n",
      "Epoch 892/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0761 - accuracy: 0.9683 - val_loss: 0.0722 - val_accuracy: 0.9700\n",
      "Epoch 893/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0719 - accuracy: 0.9737 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0735 - accuracy: 0.9693 - val_loss: 0.0430 - val_accuracy: 0.9900\n",
      "Epoch 895/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0642 - accuracy: 0.9756 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
      "Epoch 896/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0778 - accuracy: 0.9702 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0627 - accuracy: 0.9734 - val_loss: 0.0691 - val_accuracy: 0.9700\n",
      "Epoch 898/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1001 - accuracy: 0.9644 - val_loss: 0.0458 - val_accuracy: 0.9800\n",
      "Epoch 899/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0665 - accuracy: 0.9727 - val_loss: 0.0498 - val_accuracy: 0.9800\n",
      "Epoch 900/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0715 - accuracy: 0.9701 - val_loss: 0.0449 - val_accuracy: 0.9800\n",
      "Epoch 901/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0760 - accuracy: 0.9685 - val_loss: 0.0483 - val_accuracy: 0.9900\n",
      "Epoch 902/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0641 - accuracy: 0.9818 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
      "Epoch 903/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0798 - accuracy: 0.9642 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0818 - accuracy: 0.9650 - val_loss: 0.0510 - val_accuracy: 0.9800\n",
      "Epoch 905/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0708 - accuracy: 0.9742 - val_loss: 0.0456 - val_accuracy: 0.9900\n",
      "Epoch 906/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0775 - accuracy: 0.9722 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0796 - accuracy: 0.9655 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0723 - accuracy: 0.9684 - val_loss: 0.0425 - val_accuracy: 0.9900\n",
      "Epoch 909/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0755 - accuracy: 0.9718 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 910/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0601 - accuracy: 0.9736 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0767 - accuracy: 0.9698 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0819 - accuracy: 0.9643 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0659 - accuracy: 0.9704 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 914/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0760 - accuracy: 0.9682 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0665 - accuracy: 0.9687 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0721 - accuracy: 0.9657 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 917/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0553 - accuracy: 0.9805 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0605 - accuracy: 0.9729 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0670 - accuracy: 0.9688 - val_loss: 0.0731 - val_accuracy: 0.9700\n",
      "Epoch 920/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0798 - accuracy: 0.9745 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0746 - accuracy: 0.9654 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
      "Epoch 922/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0824 - accuracy: 0.9663 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 923/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0729 - accuracy: 0.9667 - val_loss: 0.0478 - val_accuracy: 0.9900\n",
      "Epoch 924/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0744 - accuracy: 0.9719 - val_loss: 0.0428 - val_accuracy: 0.9900\n",
      "Epoch 925/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0718 - accuracy: 0.9745 - val_loss: 0.0418 - val_accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0677 - accuracy: 0.9712 - val_loss: 0.0405 - val_accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0634 - accuracy: 0.9750 - val_loss: 0.0468 - val_accuracy: 0.9800\n",
      "Epoch 928/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0747 - accuracy: 0.9687 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0663 - accuracy: 0.9775 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0618 - accuracy: 0.9746 - val_loss: 0.0405 - val_accuracy: 1.0000\n",
      "Epoch 931/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0974 - accuracy: 0.9570 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0631 - accuracy: 0.9730 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 933/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0804 - accuracy: 0.9686 - val_loss: 0.0627 - val_accuracy: 0.9700\n",
      "Epoch 934/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0778 - accuracy: 0.9754 - val_loss: 0.0444 - val_accuracy: 0.9900\n",
      "Epoch 935/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0702 - accuracy: 0.9731 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 936/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0614 - accuracy: 0.9768 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0768 - accuracy: 0.9668 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
      "Epoch 938/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0713 - accuracy: 0.9683 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0725 - accuracy: 0.9714 - val_loss: 0.0566 - val_accuracy: 0.9900\n",
      "Epoch 940/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1190 - accuracy: 0.9457 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0817 - accuracy: 0.9691 - val_loss: 0.0529 - val_accuracy: 0.9700\n",
      "Epoch 942/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0672 - accuracy: 0.9803 - val_loss: 0.0552 - val_accuracy: 0.9800\n",
      "Epoch 943/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1278 - accuracy: 0.9441 - val_loss: 0.0430 - val_accuracy: 0.9900\n",
      "Epoch 944/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0725 - accuracy: 0.9680 - val_loss: 0.0450 - val_accuracy: 0.9900\n",
      "Epoch 945/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0678 - accuracy: 0.9722 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "Epoch 946/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0713 - accuracy: 0.9665 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0808 - accuracy: 0.9654 - val_loss: 0.1441 - val_accuracy: 0.9200\n",
      "Epoch 948/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1082 - accuracy: 0.9652 - val_loss: 0.0625 - val_accuracy: 0.9700\n",
      "Epoch 949/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0734 - accuracy: 0.9730 - val_loss: 0.0521 - val_accuracy: 0.9800\n",
      "Epoch 950/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0750 - accuracy: 0.9720 - val_loss: 0.0458 - val_accuracy: 0.9900\n",
      "Epoch 951/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0707 - accuracy: 0.9683 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0773 - accuracy: 0.9729 - val_loss: 0.0425 - val_accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0713 - accuracy: 0.9729 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0686 - accuracy: 0.9699 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0722 - accuracy: 0.9682 - val_loss: 0.0453 - val_accuracy: 0.9800\n",
      "Epoch 956/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0664 - accuracy: 0.9755 - val_loss: 0.0374 - val_accuracy: 1.0000\n",
      "Epoch 957/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0821 - accuracy: 0.9650 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.0718 - accuracy: 0.9652 - val_loss: 0.0500 - val_accuracy: 0.9800\n",
      "Epoch 959/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0856 - accuracy: 0.9646 - val_loss: 0.0433 - val_accuracy: 0.9900\n",
      "Epoch 960/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0667 - accuracy: 0.9698 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0780 - accuracy: 0.9660 - val_loss: 0.0429 - val_accuracy: 0.9900\n",
      "Epoch 962/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0655 - accuracy: 0.9759 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0711 - accuracy: 0.9666 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.9701 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
      "Epoch 965/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0795 - accuracy: 0.9612 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0654 - accuracy: 0.9702 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 967/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0737 - accuracy: 0.9682 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0765 - accuracy: 0.9688 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0739 - accuracy: 0.9700 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0674 - accuracy: 0.9745 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 971/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0630 - accuracy: 0.9769 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0739 - accuracy: 0.9680 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 973/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0691 - accuracy: 0.9751 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0651 - accuracy: 0.9692 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0678 - accuracy: 0.9757 - val_loss: 0.0623 - val_accuracy: 0.9800\n",
      "Epoch 976/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1120 - accuracy: 0.9514 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 977/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0692 - accuracy: 0.9721 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0738 - accuracy: 0.9666 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0714 - accuracy: 0.9710 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 980/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0766 - accuracy: 0.9701 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0772 - accuracy: 0.9713 - val_loss: 0.1330 - val_accuracy: 0.9300\n",
      "Epoch 982/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0986 - accuracy: 0.9605 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0653 - accuracy: 0.9767 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0709 - accuracy: 0.9710 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0674 - accuracy: 0.9701 - val_loss: 0.0522 - val_accuracy: 0.9900\n",
      "Epoch 986/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0967 - accuracy: 0.9560 - val_loss: 0.0432 - val_accuracy: 0.9900\n",
      "Epoch 987/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0745 - accuracy: 0.9702 - val_loss: 0.0409 - val_accuracy: 0.9900\n",
      "Epoch 988/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0774 - accuracy: 0.9672 - val_loss: 0.0386 - val_accuracy: 0.9900\n",
      "Epoch 989/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0765 - accuracy: 0.9640 - val_loss: 0.0395 - val_accuracy: 0.9900\n",
      "Epoch 990/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0678 - accuracy: 0.9706 - val_loss: 0.0395 - val_accuracy: 0.9900\n",
      "Epoch 991/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0744 - accuracy: 0.9677 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 992/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.9645 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0788 - accuracy: 0.9629 - val_loss: 0.0403 - val_accuracy: 0.9900\n",
      "Epoch 994/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0762 - accuracy: 0.9743 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
      "Epoch 995/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0633 - accuracy: 0.9723 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
      "Epoch 996/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0621 - accuracy: 0.9739 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0691 - accuracy: 0.9748 - val_loss: 0.0895 - val_accuracy: 0.9400\n",
      "Epoch 998/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0873 - accuracy: 0.9687 - val_loss: 0.0524 - val_accuracy: 0.9900\n",
      "Epoch 999/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0756 - accuracy: 0.9761 - val_loss: 0.0422 - val_accuracy: 0.9900\n",
      "Epoch 1000/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0660 - accuracy: 0.9738 - val_loss: 0.0380 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8608646810>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    epochs=1000,\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03804000839591026, 1.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
